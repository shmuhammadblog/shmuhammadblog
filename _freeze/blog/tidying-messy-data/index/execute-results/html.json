{
  "hash": "b008d6228bbf050caa0e0a403f9d56c9",
  "result": {
    "markdown": "---\ntitle: How to Tidy Messy Data  Part 1\ndate: 2022-01-09\ndraft: false\ntags:\n- tutorial\n- Rstat\n# Featured image\n# To use, add an image named `featured.jpg/png` to your page's folder.\n# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width\n# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight\nimage: featured.jpg\n---\n\nData scientist often spent about 80% of data analysis process on cleaning and preparing data[^1].Worst still, cleaning and preparing the data is an iterative process. Hadley Wickham refer to this process of cleaning and preparing data as **data tidying**: structuring datasets to facilitate analysis. Therefore, it is very important to get the right tool to efficiently and quickly tidy any messy data and spend more time working on your analysis.\n\n[^1]: [Tidy Data : Hadley Wikham](https://vita.had.co.nz/papers/tidy-data.pdf)\n\n<center>\n![Tidydata](tidydata.png)\n</center>\n\nI mostly use Python for machine learning. But R is an exceptional tool for data manipulation, data visualization, and data analysis due to the many available packages in R developed mainly for data analysis. R is becoming the \"de facto best tool\" for data analysis. Therefore, we will use R to explore different ways to tidy data. In this part 1 series, we will gently start by exploring the `Janitor`[^2] package and see how it makes tidying data easy. In subsequent series, we will explore `dplyr`[^3] and `tidyr`[^4] packages which are the most complete packages for data manipulaton and tidying data.\n\n[^2]: [The janitor package](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html)\n\n[^3]: [dplyr the grammar of data manipulation](https://dplyr.tidyverse.org/)\n\n[^4]: [Tidyr](https://tidyr.tidyverse.org/articles/tidy-data.html)\n\n\n<center>\n![R Vs Python ](rpython.jpg)\n</center>\n\n## Janitor Package\n\nThe janitor package has user-friendly functions for tidying messy data. It provides functions for formating column names, detecting duplicate records, provide quick tabulations, and many more.\n\nFor the purpose of this series, we are going to use a [pinguin dataset](https://github.com/BrunoGrandePhD/2020-11-14-rladies-workshop/blob/main/learnr-tutorial/messy_penguins.cs) that has been deliberately messed. \n\nLoading the required packages\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(janitor) # CRAN v2.1.0\nlibrary(tidyverse) # CRAN v1.3.0\n```\n:::\n\nLoading the dataset from [Github](%22https://raw.githubusercontent.com/BrunoGrandePhD/2020-11-14-rladies-workshop/rladies-tunis/learnr-tutorial/messy_penguins.csv).\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_penguins <- read_csv(\"https://raw.githubusercontent.com/BrunoGrandePhD/2020-11-14-rladies-workshop/rladies-tunis/learnr-tutorial/messy_penguins.csv\")\n```\n:::\n\nObserving the data\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(messy_penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 344\nColumns: 18\n$ studyName             <chr> \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL…\n$ `Sample Number`       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ Species               <chr> \"Adelie Penguin (Pygoscelis adeliae)\", NA, NA, N…\n$ Region                <chr> \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\"…\n$ Island                <chr> NA, NA, \"Torgersen\", NA, NA, NA, NA, NA, NA, NA,…\n$ Stage                 <chr> \"Adult, 2 Egg Stage\", \"Adult, 1 Egg Stage\", \"Juv…\n$ `Individual ID`       <chr> \"N1A1\", \"N1A2\", \"N2A1\", \"N2A2\", \"N3A1\", \"N3A2\", …\n$ `Clutch Completion`   <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ `Date Egg`            <chr> \"11/11/07\", \"11/11/07\", \"11/16/07\", \"11/16/07\", …\n$ `Culmen Length (mm)`  <chr> \"39.1\", \"39.5\", \"40.3\", NA, \"36.7\", \"39.3\", \"38.…\n$ Nickname              <chr> \"Kamile\", \"Dixie\", \"Arian\", \"Alexander\", \"Dewi\",…\n$ `Culmen Depth (mm)`   <chr> \"18.7\", \"17.4\", \"18\", \"-\", \"19.3\", \"20.6\", \"17.8…\n$ `Flipper Length (mm)` <chr> \"181\", \"186\", \"195\", \"--\", \"193\", \"190\", \"181\", …\n$ `Body Mass`           <chr> \"3750 g\", \"3800g\", \"3250\", NA, \"3450 grams\", \"36…\n$ Sex                   <chr> \"M\", \"FEMALE\", \"FEMALE\", NA, \"FEMALE\", \"MALE\", \"…\n$ `Delta 15 N (o/oo)`   <chr> NA, \"8.94956\", \"8.36821\", NA, \"8.76651\", \"8.6649…\n$ `Delta 13 C (o/oo)`   <chr> NA, \"-24.69454\", \"-25.33302\", NA, \"-25.32426\", \"…\n$ Comments              <chr> \"Not enough blood for isotopes.\", NA, NA, \"Adult…\n```\n:::\n:::\n\n### `clean_names()` function\n\nThe `clean_names()` handles problematic variable names, returning only lowercase letters with underscore as separator, appends numbers to duplicated names, andles special characters and spaces, and converts \"%\" to \"percent\" to retain meaning. clean_names() can only be use on dataframe like objects, other objects such as named lists and vectors, `make_clean_names()` is used.\n\nLet us observe column names for our messy data\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(messy_penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Nickname\"            \"Culmen Depth (mm)\"  \n[13] \"Flipper Length (mm)\" \"Body Mass\"           \"Sex\"                \n[16] \"Delta 15 N (o/oo)\"   \"Delta 13 C (o/oo)\"   \"Comments\"           \n```\n:::\n:::\n\nWe can see that, the column names structure is not uniform ( e.g \"studyName\", \"Sample Number\", \"Delta 15 N (o/oo)\"). So, to tidy these column names, we can use the `clean_names()` function to change them to uniform structure.\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_penguins <- clean_names(messy_penguins)\n\ncolnames(tidy_penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"study_name\"        \"sample_number\"     \"species\"          \n [4] \"region\"            \"island\"            \"stage\"            \n [7] \"individual_id\"     \"clutch_completion\" \"date_egg\"         \n[10] \"culmen_length_mm\"  \"nickname\"          \"culmen_depth_mm\"  \n[13] \"flipper_length_mm\" \"body_mass\"         \"sex\"              \n[16] \"delta_15_n_o_oo\"   \"delta_13_c_o_oo\"   \"comments\"         \n```\n:::\n:::\n\nNow, all the column names are change to lower-case and have consistent structure. By default, `clean_names()` return snake-case like names, but you can specify other options such as the following cases:\n\n-   snake_case: \"snake\"\n-   lowerCamel: \"lower_camel\" or \"small_camel\"\n-   UpperCamel: \"upper_camel\" or \"big_camel\"\n-   ALL_CAPS: \"all_caps\" or \"screaming_snake\"\n-   lowerUPPER: \"lower_upper\"\n-   UPPERlower: \"upper_lower\"\n-   Sentence case: \"sentence\"\n-   Title Case: \"title\"\n\nYou can get details about any case [here](https://rdrr.io/cran/snakecase/man/to_any_case.html)\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_penguins %>%\n  clean_names(case = \"lower_camel\") %>%\n  colnames()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"studyName\"        \"sampleNumber\"     \"species\"          \"region\"          \n [5] \"island\"           \"stage\"            \"individualId\"     \"clutchCompletion\"\n [9] \"dateEgg\"          \"culmenLengthMm\"   \"nickname\"         \"culmenDepthMm\"   \n[13] \"flipperLengthMm\"  \"bodyMass\"         \"sex\"              \"delta15NOOo\"     \n[17] \"delta13COOo\"      \"comments\"        \n```\n:::\n:::\n\nTo clean names, but leave some abbreviations to appear the way you want.\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_penguins %>%\n  clean_names(case = \"lower_camel\", abbreviations = c(\"ID\", \"N\", \"mm\")) %>%\n  colnames()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"studyNAme\"        \"sampleNUmber\"     \"species\"          \"region\"          \n [5] \"island\"           \"stage\"            \"individualID\"     \"clutchCompletion\"\n [9] \"dateEgg\"          \"culmenLengthMm\"   \"nIckname\"         \"culmenDepthMm\"   \n[13] \"flipperLengthMm\"  \"bodyMass\"         \"sex\"              \"delta15NOOo\"     \n[17] \"delta13COOo\"      \"comments\"        \n```\n:::\n:::\n\nYou can also restore column names to Title Case, e.g., for plotting\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_penguins %>%\n  clean_names(case = \"title\") %>%\n  colnames()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Study Name\"        \"Sample Number\"     \"Species\"          \n [4] \"Region\"            \"Island\"            \"Stage\"            \n [7] \"Individual Id\"     \"Clutch Completion\" \"Date Egg\"         \n[10] \"Culmen Length Mm\"  \"Nickname\"          \"Culmen Depth Mm\"  \n[13] \"Flipper Length Mm\" \"Body Mass\"         \"Sex\"              \n[16] \"Delta 15 n o Oo\"   \"Delta 13 c o Oo\"   \"Comments\"         \n```\n:::\n:::\n\nFor vectors, we can use `make_clean_names` functions.\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- structure(1:4, names = c(\"This is first\", \"this issecond\", \"3rd\", \"FinalChoice\"))\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is first this issecond           3rd   FinalChoice \n            1             2             3             4 \n```\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(x) <- make_clean_names(names(x)) # `x` is added to names that start with number\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nthis_is_first this_issecond          x3rd  final_choice \n            1             2             3             4 \n```\n:::\n:::\n\n\n\n### `tabyl()` function\n\nThis function is an alternative to the `table()` function from base-R. The function generate a frequency table from either a dataframe or vector.\n\n::: {.cell}\n\n```{.r .cell-code}\nstudynames <- messy_penguins %>%\n  clean_names() %>%\n  tabyl(study_name) # %>%\n# adorn_pct_formatting(digits = 0, affix_sign = TRUE) # creates a percentage column\n\nstudynames\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n study_name   n   percent\n    PAL0708 110 0.3197674\n    PAL0809 114 0.3313953\n    PAL0910 120 0.3488372\n```\n:::\n:::\n\nAfter `tabyl()` function, we can use the janitor's family of adorn_functions to format the resultant dataframes.\n\n::: {.cell}\n\n```{.r .cell-code}\nstudynames <- messy_penguins %>%\n  clean_names() %>%\n  tabyl(study_name) %>%\n  adorn_pct_formatting(digits = 0, affix_sign = TRUE) %>% # format the percentage column\n  adorn_totals(where = \"row\") # %>%  #Add totals\n\n\nstudynames\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n study_name   n percent\n    PAL0708 110     32%\n    PAL0809 114     33%\n    PAL0910 120     35%\n      Total 344       -\n```\n:::\n:::\n\nOther adorn functions are :\n\n-   `adorn_pct_formatting` Format a data.frame of decimals as percentages\n-   `adorn_rounding` Round the numeric columns in a data.frame\n-   `adorn_totals` Add a totals row and/or column to a data.frame.\n-   `adorn_ns` Add underlying Ns to a tabyl displaying percentages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars %>%\n  tabyl(am, cyl) %>%\n  adorn_percentages(\"col\") %>%\n  adorn_totals(where = c(\"row\", \"col\")) %>%\n  adorn_pct_formatting(digits = 0) %>%\n  adorn_rounding(digits = 3) %>%\n  adorn_ns(position = \"front\") # %>%\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    am         4        6         8     Total\n     0  3  (27%) 4  (57%) 12  (86%) 19 (170%)\n     1  8  (73%) 3  (43%)  2  (14%) 13 (130%)\n Total 11 (100%) 7 (100%) 14 (100%) 32 (300%)\n```\n:::\n:::\n\nLet use compare with Base-R `table()` function:\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_names <- messy_penguins %>%\n  clean_names()\n\ntable(tidy_names$study_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nPAL0708 PAL0809 PAL0910 \n    110     114     120 \n```\n:::\n:::\n\nIf you have a vector, the function also works the same\n\n::: {.cell}\n\n```{.r .cell-code}\nAge <- c(23, 24, 24, 25, 23, 26, 25)\ntabyl(Age)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Age n   percent\n  23 2 0.2857143\n  24 2 0.2857143\n  25 2 0.2857143\n  26 1 0.1428571\n```\n:::\n:::\n\n### `remove_empty()`\n\nThis functions usage is straight foward. It simply removes any colum/rows from a data.frame or matrix that contain all \"NA\" as their entries.\n\n::: {.cell}\n\n```{.r .cell-code}\nempty <- messy_penguins %>%\n  remove_empty() # this will remove both empty rows and columns by default.\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nvalue for \"which\" not specified, defaulting to c(\"rows\", \"cols\")\n```\n:::\n\n```{.r .cell-code}\nempty <- messy_penguins %>%\n  remove_empty(which = \"rows\", quiet = TRUE) # specify row or column and use quite argument to supress  messages be suppressed (TRUE) or printed (FALSE) indicating the summary of empty columns or rows removed?\n```\n:::\n\n### `remove-constant()`\n\nSometimes, we may need to find columns that have the same values, we can use `remove-constant()` to to do that.\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(A = 1, B = 1:3, c = c(3, 3, 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  A B c\n1 1 1 3\n2 1 2 3\n3 1 3 3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(A = 1, B = 1:3, c = c(3, 3, 3)) %>%\n  dplyr::select_at(setdiff(names(.), names(remove_constant(.)))) %>%\n  unique()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  A c\n1 1 3\n```\n:::\n:::\n\n### `get_dupes()` to Remove duplicates\n\nSometimes our data may contains duplicates that we may not like. So, we need to find and possibly remove them if any. `get_dupes()` returns a records (and inserts a count of duplicates) so that we can deal with identfied cases accordingly.\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_penguins %>%\n  clean_names() %>%\n  get_dupes() # This dataset no any duplicate.\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNo variable names specified - using all columns.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nNo duplicate combinations found of: study_name, sample_number, species, region, island, stage, individual_id, clutch_completion, date_egg, ... and 9 other variables\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 0 × 19\n# … with 19 variables: study_name <chr>, sample_number <dbl>, species <chr>,\n#   region <chr>, island <chr>, stage <chr>, individual_id <chr>,\n#   clutch_completion <chr>, date_egg <chr>, culmen_length_mm <chr>,\n#   nickname <chr>, culmen_depth_mm <chr>, flipper_length_mm <chr>,\n#   body_mass <chr>, sex <chr>, delta_15_n_o_oo <chr>, delta_13_c_o_oo <chr>,\n#   comments <chr>, dupe_count <int>\n```\n:::\n:::\n\n\nTip: call clean_names() every time you read in a new data set to automatically clean column names.\n\n<style>\nbody {\ntext-align: justify}\n</style>\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}