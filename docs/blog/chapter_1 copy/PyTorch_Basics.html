<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-99.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-04-18">
<meta name="description" content="It discussed how deep learning changes our approach to machine learning and why PyTorch is a good fit for deep learning">

<title>Shamsuddeen Hassan Muhammad’s Blog - NLP with PyTorch</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-124900795-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script defer="" data-domain="ivelasq.rbind.io" src="https://plausible.io/js/plausible.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Shamsuddeen Hassan Muhammad’s Blog - NLP with PyTorch">
<meta name="twitter:description" content="It discussed how deep learning changes our approach to machine learning and why PyTorch is a good fit for deep learning">
<meta name="twitter:image" content="https://shmuhammadblog.github.io/blog/chapter_1 copy/book_pic.png">
<meta name="twitter:creator" content="Shamsuddeen Hassan Muhammad">
<meta name="twitter:site" content="@shmuhammadd">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Shamsuddeen Hassan Muhammad</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="dropdown-header">
 <span class="menu-text">NLP Researcher and Data Scientist</span></li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../til.html" rel="" target="">
 <span class="menu-text">Today I Learned</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Shmuhammadd" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/shmuhammad2004" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/shmuhammad/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">NLP with PyTorch</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Pytorch</div>
    <div class="quarto-category">Books</div>
  </div>
  </div>

<div>
  <div class="description">
    It discussed how deep learning changes our approach to machine learning and why PyTorch is a good fit for deep learning
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 18, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="book-natural-language-processing-with-pytorch" class="level1">
<h1>Book: Natural Language Processing with Pytorch</h1>
<ul>
<li><p>Aims to bring newcomers to natural language processing and deep learning using Pytorch</p></li>
<li><p>Mathematics in most places have been avoided because it is a distraction from the main goal of this book</p></li>
</ul>
<section id="chapter-1-introduction-to-nlp-and-pytorch-basics" class="level2">
<h2 class="anchored" data-anchor-id="chapter-1-introduction-to-nlp-and-pytorch-basics">Chapter 1: Introduction to NLP and PyTorch Basics</h2>
<blockquote class="blockquote">
<p>Goal:</p>
</blockquote>
<ul>
<li><p>1: Develop a clear understanding of the supervised learning paradigm</p></li>
<li><p>2: Learn how to encode inputs for the learning tasks.</p></li>
<li><p>3: Master the basics of PyTorch.</p></li>
</ul>
</section>
<section id="machine-learning-vs-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-vs-deep-learning">Machine Learning vs Deep Learning</h2>
<p><img src="./machine_vs_deep.png" class="img-fluid"></p>
</section>
</section>
<section id="types-of-learning" class="level1">
<h1>Types of Learning</h1>
<ul>
<li><p>Supervised Learning:</p></li>
<li><p>Unsupervised Learning:</p></li>
<li><p>Semi-supervised Learning:</p></li>
</ul>
<p><img src="./supervised_unsupervised_Semisuperved.png" class="img-fluid"></p>
<section id="supervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h2>
<blockquote class="blockquote">
<p>Supervised learning then becomes a process of finding the optimal parameters/weights w that will minimize the cumulative loss for all the n examples.</p>
</blockquote>
<p><img src="./supervised_learning.png" class="img-fluid"></p>
</section>
<section id="how-to-represent-data-data-encoding" class="level2">
<h2 class="anchored" data-anchor-id="how-to-represent-data-data-encoding">How to represent data: Data Encoding ?</h2>
<ul>
<li><p>How can we represent our inputs and targets in NLP problems numerically so that we can train our model?</p></li>
<li><p>We will need to represent both observations (text) and target numerically to use them in with machine learning algorithm— Encoding.</p></li>
</ul>
<p><img src="./encoding1.png" class="img-fluid"></p>
<ul>
<li><p>There are many ways to perform this encoding (one-hot encoding, BoW, embeddings etc).</p></li>
<li><p>This book is dedicated to learning such representations for a task from data. However, we begin with some simple count­based representations that are based on heuristics.</p></li>
<li><p>Though simple, they are incredibly powerful as they are and can serve as a starting point for richer representation learning. All of these count­based representations start with a vector of fixed dimension.</p></li>
</ul>
</section>
<section id="one-hot-representation" class="level2">
<h2 class="anchored" data-anchor-id="one-hot-representation">One-Hot Representation</h2>
<ul>
<li><p>The one­hot representation, as the name suggests, starts with a zero vector, and sets as 1 the corresponding entry in the vector if the word is present in the sentence or document</p></li>
<li><p>is a technique for representing categorical variables as binary vectors.</p></li>
</ul>
<section id="example" class="level4">
<h4 class="anchored" data-anchor-id="example">Example</h4>
<p><img src="./onehot1.png" class="img-fluid"> <img src="./onehot2.png" class="img-fluid"></p>
<ul>
<li><p>Tesla is represented as a vector of length 5 ([1,0,0,0,0])</p></li>
<li><p>Therefore the list of words in the sentence can be represented as an array of vectors or a matrix</p></li>
</ul>
</section>
<section id="example-1" class="level3">
<h3 class="anchored" data-anchor-id="example-1">Example</h3>
<p>Assume you have the following two sentences</p>
<ul>
<li><p>Time flies like an arrow.</p></li>
<li><p>Fruit flies like a banana.</p></li>
</ul>
<p>Tokenizing the sentences, ignoring punctuation, and treating everything as lowercase, will yield a vocabulary of size 8:{time, fruit, flies, like, a, an, arrow, banana}</p>
<p><img src="./onehot.png" class="img-fluid"></p>
<p>The binary encoding for “like a banana” would then be :[0, 0, 0, 1, 1, 0, 0, 1].</p>
</section>
</section>
<section id="term-frequency-tf" class="level2">
<h2 class="anchored" data-anchor-id="term-frequency-tf">Term Frequency (TF)</h2>
<ul>
<li><p>The term frequency (TF) is the number of times a word appears in a document.</p></li>
<li><p>is a measure of how important a word is to a document.</p></li>
<li><p>From previous example, the sentence “Fruit flies like time flies a fruit” has the following term frequency representation: [1, 2, 2, 1, 1, 0, 0, 0].</p></li>
</ul>
</section>
<section id="term-frequency-inverse-document-frequency-tf-idf" class="level2">
<h2 class="anchored" data-anchor-id="term-frequency-inverse-document-frequency-tf-idf">Term Frequency-Inverse Document Frequency (TF-IDF)</h2>
<ul>
<li><p>The TF representation weights words proportionally to their frequency.</p></li>
<li><p>However, common words such as “the” do not add anything to our understanding of a specific patent.</p></li>
<li><p>Conversely, if a rare word (such as “excellent”) occurs less frequently but is quite likely to be indicative of the nature of the document, we would want to give it a larger weight in our representation.</p></li>
<li><p>The Inverse­ Document­Frequency (IDF) is a heuristic to do exactly that: by taking inverse document frequency, we can minimize the weighting of frequent terms while making infrequent terms have a higher impact</p></li>
<li><p>Therefore, IDF representation penalizes common tokens and rewards rare tokens in the vector representation</p></li>
</ul>
<p><img src="./idf.png" class="img-fluid"></p>
<ul>
<li>TF-IDF stands for term frequency-inverse document frequency and it is a measure, used in the fields of information retrieval (IR) and machine learning, that can quantify the importance or relevance of string representations (words, phrases, lemmas, etc) in a document amongst a collection of documents.</li>
</ul>
<p><img src="./tfidf.png" class="img-fluid"></p>
<ul>
<li><p>The key intuition motivating TF-IDF is the importance of a term is inversely related to its frequency across documents.</p></li>
<li><p><strong>TF</strong> gives us information on how often a term appears in a document and <strong>IDF</strong> gives us information about the relative rarity of a term in the collection of documents. By multiplying these values together we can get our final TF-IDF value.</p></li>
<li><p>The higher the TF-IDF score the more important or relevant the term is; as a term gets less relevant, its TF-IDF score will approach 0.</p></li>
</ul>
<div id="cell-31" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfTransformer  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>corpus<span class="op">=</span>[<span class="st">"I come to China to travel"</span>, </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"This is a car polupar in China"</span>,          </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I love tea and Apple "</span>,   </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The work is to write some papers in science"</span>] </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>vectorizer<span class="op">=</span>CountVectorizer()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>transformer <span class="op">=</span> TfidfTransformer()</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>tfidf <span class="op">=</span> transformer.fit_transform(vectorizer.fit_transform(corpus))  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (tfidf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (0, 16)   0.4424621378947393
  (0, 15)   0.697684463383976
  (0, 4)    0.4424621378947393
  (0, 3)    0.348842231691988
  (1, 14)   0.45338639737285463
  (1, 9)    0.45338639737285463
  (1, 6)    0.3574550433419527
  (1, 5)    0.3574550433419527
  (1, 3)    0.3574550433419527
  (1, 2)    0.45338639737285463
  (2, 12)   0.5
  (2, 7)    0.5
  (2, 1)    0.5
  (2, 0)    0.5
  (3, 18)   0.3565798233381452
  (3, 17)   0.3565798233381452
  (3, 15)   0.2811316284405006
  (3, 13)   0.3565798233381452
  (3, 11)   0.3565798233381452
  (3, 10)   0.3565798233381452
  (3, 8)    0.3565798233381452
  (3, 6)    0.2811316284405006
  (3, 5)    0.2811316284405006</code></pre>
</div>
</div>
</section>
<section id="word-vectors-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="word-vectors-embeddings">Word Vectors: Embeddings</h2>
<ul>
<li><p>In deep learning, we used embeddings to learn a representation that is more robust to the nature of the data.</p></li>
<li><p>Embeddings are a way to represent words in a vector space and capture semantic information about the words in a sentence.</p></li>
<li><p>Example of embeddings: Word2Vec, Glove, FastText, WordEmbeddings,HauWE etc.</p></li>
</ul>
<blockquote class="blockquote">
<p>Word Embeddings or Word vectorization is a methodology in NLP to map words or phrases from vocabulary to a corresponding vector of real numbers which used to find word predictions, word similarities/semantics. The process of converting words into numbers are called Vectorization</p>
</blockquote>
<p><img src="./wordembedding.png" class="img-fluid"></p>
</section>
</section>
<section id="pytorch-basics" class="level1">
<h1>PyTorch Basics</h1>
<ul>
<li><p>PyTorch is an open source, community ­driven deep toolkit for building neural networks that are optimized for the task of image, text, and sequence classification.</p></li>
<li><p>It is dynamic graph-based framework that allows you to define your neural network in a way that is easy to understand and debug.</p></li>
</ul>
<section id="why-use-pytorch" class="level2">
<h2 class="anchored" data-anchor-id="why-use-pytorch">Why use PyTorch?</h2>
<ul>
<li><p>PyTorch is the most used deep learning framework today. See more at <a href="https://paperswithcode.com/trends">here</a>.</p></li>
<li><p>PyTorch also helps take care of many things such as GPU acceleration (making your code run faster) behind the scenes.</p></li>
</ul>
</section>
<section id="pytoch-installation" class="level2">
<h2 class="anchored" data-anchor-id="pytoch-installation">Pytoch Installation</h2>
<ul>
<li><p>pre-requisite: Package Manager (e.g.&nbsp;pip, conda)</p></li>
<li><p>Python</p></li>
<li><p>PyTorch version (the book supoort 1.0), Now Pytorch recent version is 1.4.0. So, expect some stuff to break in the book.</p></li>
</ul>
</section>
<section id="verification" class="level2">
<h2 class="anchored" data-anchor-id="verification">VERIFICATION</h2>
<div id="cell-41" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1234</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>torch.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/datascience/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>'1.13.0.dev20220611'</code></pre>
</div>
</div>
</section>
<section id="what-is-tensor" class="level2">
<h2 class="anchored" data-anchor-id="what-is-tensor">What is Tensor</h2>
<ul>
<li><p>Tensor are the standard way of representing data in Pytorch, such as text, images, and audio.</p></li>
<li><p>Their job is to represent data in a numerical way.</p></li>
</ul>
<p><img src="./tensor_represent_data.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>You could have a vector [3, 2] to describe [bedrooms, bathrooms] in your house. Or you could have [3, 2, 2] to describe [bedrooms, bathrooms, car_parks] in your house.</p>
</blockquote>
<p><img src="./tensor_loop.png" class="img-fluid"></p>
</section>
</section>
<section id="is-tensor-all-you-need" class="level1">
<h1>is Tensor all you need?</h1>
<ul>
<li><p>Data Structure for holding data:</p>
<ul>
<li><p>Python List,</p></li>
<li><p>Numpy Array, and</p></li>
<li><p>Torch Tensor</p></li>
</ul></li>
<li><p>Let us remember the basic of data structures in Python (List and Numpy Array) before we start using Pytorch Tensor</p></li>
</ul>
<section id="from-python-lists-to-numpy-array" class="level3">
<h3 class="anchored" data-anchor-id="from-python-lists-to-numpy-array">From Python lists to Numpy Array</h3>
<ul>
<li>Python does not have built-in support for Arrays, but Python Lists can be used instead.</li>
</ul>
<div id="cell-49" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>a_list <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">4</span>] <span class="co">#A list is the Python equivalent of an array</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>a_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>[1, 3, 4]</code></pre>
</div>
</div>
<div id="cell-50" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>list</code></pre>
</div>
</div>
<div id="cell-51" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>a_list[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>1</code></pre>
</div>
</div>
<div id="cell-52" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>a_numpy <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">4</span>])</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>a_numpy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>array([1, 3, 4])</code></pre>
</div>
</div>
<div id="cell-53" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a_numpy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>numpy.ndarray</code></pre>
</div>
</div>
<div id="cell-54" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>a_numpy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([1, 3, 4])</code></pre>
</div>
</div>
<div id="cell-55" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>a_numpy[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>1</code></pre>
</div>
</div>
</section>
<section id="why-numpy" class="level3">
<h3 class="anchored" data-anchor-id="why-numpy">Why numpy?</h3>
<ul>
<li><p>Size - Numpy data structures take up less space</p></li>
<li><p>Performance - they have a need for speed and are faster than lists</p></li>
<li><p>Functionality - SciPy and NumPy have optimized functions such as linear algebra operations built in.</p></li>
</ul>
<p><img src="./contiguous.png" class="img-fluid"></p>
<div id="cell-59" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>size_of_vec <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pure_python_version():</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    t1 <span class="op">=</span> time.time()</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> <span class="bu">range</span>(size_of_vec)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> <span class="bu">range</span>(size_of_vec)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> [X[i] <span class="op">+</span> Y[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(X)) ]</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> time.time() <span class="op">-</span> t1</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> numpy_version():</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    t1 <span class="op">=</span> time.time()</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.arange(size_of_vec)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> np.arange(size_of_vec)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> X <span class="op">+</span> Y</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> time.time() <span class="op">-</span> t1</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> pure_python_version()</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> numpy_version()</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t1, t2)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Numpy is in this example "</span> <span class="op">+</span> <span class="bu">str</span>(t1<span class="op">/</span>t2) <span class="op">+</span> <span class="st">" faster!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.0001919269561767578 3.5762786865234375e-05
Numpy is in this example 5.366666666666666 faster!</code></pre>
</div>
</div>
</section>
<section id="from-numpy-array-to-torch-tensor" class="level3">
<h3 class="anchored" data-anchor-id="from-numpy-array-to-torch-tensor">From Numpy Array to Torch Tensor</h3>
<ul>
<li><p>Tensors are like arrays, both are data structures that are used to store data.</p></li>
<li><p>Tensor support GPU acceleration (Speed) and Gradients (Backpropagation)</p></li>
<li><p>Numpy arrays are mainly used in typical machine learning algorithms whereas pytorch tensors are mainly used in deep learning which requires heavy matrix computation</p></li>
</ul>
<section id="are-tensors-really-like-numpy-arrays" class="level4">
<h4 class="anchored" data-anchor-id="are-tensors-really-like-numpy-arrays">Are Tensors Really like Numpy Arrays?</h4>
<ul>
<li>Yes, they are. Let us see how they created</li>
</ul>
<blockquote class="blockquote">
<p>Numpy</p>
</blockquote>
<div id="cell-65" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>a_numpy <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>]]) <span class="co"># Create a numpy array</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_numpy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1 2 3]
 [2 3 4]]</code></pre>
</div>
</div>
<div id="cell-66" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>a_numpy.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(2, 3)</code></pre>
</div>
</div>
<div id="cell-67" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>a_numpy.size</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>6</code></pre>
</div>
</div>
<div id="cell-68" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>a_numpy.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>dtype('int64')</code></pre>
</div>
</div>
<div id="cell-69" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a_numpy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>numpy.ndarray</code></pre>
</div>
</div>
<div id="cell-70" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>a_numpy[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>array([1, 2, 3])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Tensor</p>
</blockquote>
<div id="cell-72" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>a_tensor <span class="op">=</span> torch.Tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>]]) <span class="co"># Create a PyTorch tensor</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 2., 3.],
        [2., 3., 4.]])</code></pre>
</div>
</div>
<div id="cell-73" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>a_tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>torch.Size([2, 3])</code></pre>
</div>
</div>
<div id="cell-74" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>a_tensor.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>torch.Size([2, 3])</code></pre>
</div>
</div>
<div id="cell-75" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>a_tensor.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>torch.float32</code></pre>
</div>
</div>
<div id="cell-76" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>torch.Tensor</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>A tensor is an array: that is, a data structure that stores a collection of numbers that are accessible individually using an index, and that can be indexed with multiple indices.</p>
</blockquote>
<blockquote class="blockquote">
<p>So, the most important difference between the two frameworks is naming. Numpy calls tensors (high dimensional matrices or vectors) arrays while in PyTorch there’s just called tensors. Everything else is quite similar.</p>
</blockquote>
</section>
</section>
<section id="but-wait-tensors-offer-much-more-than-just-a-data-structure." class="level2">
<h2 class="anchored" data-anchor-id="but-wait-tensors-offer-much-more-than-just-a-data-structure.">But, wait Tensors offer much more than just a data structure.</h2>
<ul>
<li><p>GPU acceleration , which is a great advantage for deep learning</p></li>
<li><p>distribute operations on multiple devices or machines, and</p></li>
<li><p>keep track of the graph of computations that created them ( usefull for backpropagation)</p></li>
</ul>
</section>
<section id="let-us-learn-more-about-tensor" class="level2">
<h2 class="anchored" data-anchor-id="let-us-learn-more-about-tensor">Let us Learn more about Tensor</h2>
<blockquote class="blockquote">
<p>Tensors are generalization of vectors and matrices to an arbitrary number of dimensions.</p>
</blockquote>
<p><img src="./tensor_generalization.png" class="img-fluid"></p>
<p><img src="./tensor.png" class="img-fluid"></p>
<section id="so-what-can-we-do-with-tensors" class="level3">
<h3 class="anchored" data-anchor-id="so-what-can-we-do-with-tensors">So, what can we do with Tensors?</h3>
<p>Various operations are available on tensors.</p>
<ul>
<li><p>Creating tensors</p></li>
<li><p>Operations with tensors</p></li>
<li><p>Indexing, slicing, and joining with tensors Computing gradients with tensors</p></li>
<li><p>Using CUDA/MPS tensors with GPUs</p></li>
</ul>
</section>
</section>
<section id="creating-tensors" class="level2">
<h2 class="anchored" data-anchor-id="creating-tensors">Creating Tensors</h2>
<ul>
<li><p>PyTorch allows us to create tensors in many different ways using the torch package.</p></li>
<li><p>The following are some of the ways to create tensors:</p></li>
</ul>
<section id="creating-random-tensor-with-a-specific-size" class="level5">
<h5 class="anchored" data-anchor-id="creating-random-tensor-with-a-specific-size">1: Creating Random Tensor with a specific size</h5>
<div id="cell-90" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>a_random <span class="op">=</span> torch.Tensor(size <span class="op">=</span> (<span class="dv">3</span>,<span class="dv">4</span>)) <span class="co"># Create a random tensor</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a_numpy = np.array([3,4])</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.0000e+00, 2.0000e+00, 0.0000e+00, 2.0000e+00],
        [4.8673e-39, 4.5810e-41, 6.1522e-36, 1.4013e-45],
        [8.4015e-40, 4.5810e-41, 4.7625e-10, 4.5810e-41]])</code></pre>
</div>
</div>
<div id="cell-91" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.shape)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.size())</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(a_random))</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.<span class="bu">type</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 4])
torch.Size([3, 4])
&lt;class 'torch.Tensor'&gt;
torch.FloatTensor</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: .shape is an alias for .size(), and was added to closely match numpy !</p>
</blockquote>
<blockquote class="blockquote">
<p>Note: The default tensor type when you use the torch.Tensor constructor is torch.FloatTensor.</p>
</blockquote>
<p>Infact, <code>torch.Tensor</code> is an alias for the default tensor type (torch.FloatTensor).</p>
<div id="cell-95" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>a_random <span class="op">=</span> torch.FloatTensor((<span class="dv">3</span>,<span class="dv">4</span>)) <span class="co"># Create a random tensor</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.<span class="bu">type</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.FloatTensor</code></pre>
</div>
</div>
<ul>
<li><p>But, what if I want my tensor to represent the data type I use?</p>
<ul>
<li><code>torch.tensor</code> constructor infers the dtype automatically</li>
</ul></li>
</ul>
<div id="cell-97" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>a_random <span class="op">=</span> torch.tensor((<span class="dv">3</span>,<span class="dv">4</span>)) <span class="co"># Create a random tensor</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.dtype)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.int64</code></pre>
</div>
</div>
<p>But, you can also specify the dtype explicitly.</p>
<div id="cell-99" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>a_torch <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_torch.<span class="bu">type</span>()) <span class="co"># Tensor type</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.FloatTensor</code></pre>
</div>
</div>
<p>I would recommend to stick to torch.tensor, if you would like to change the type, you can change</p>
<ul>
<li>What of if I have existing Tensor and what should I do with it?</li>
</ul>
<div id="cell-102" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>a_torch <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_torch.<span class="bu">type</span>()) <span class="co"># Tensor type</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_torch.size()) <span class="co"># Tensor Size</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.LongTensor
torch.Size([3])</code></pre>
</div>
</div>
<div id="cell-103" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>a_short <span class="op">=</span>  a_torch.short() <span class="co"># Convert to short, float(), </span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_short.<span class="bu">type</span>()) <span class="co"># Tensor type</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.ShortTensor</code></pre>
</div>
</div>
<p><a href="https://pytorch.org/docs/stable/tensors.html#data-types">See different Pytorch Data Types</a>: Torch defines 10 tensor types with CPU and GPU variants:</p>
<ul>
<li><p>The most common type (and generally the default) is torch.float32 or torch.float. This is referred to as “32-bit floating point”.</p></li>
<li><p>But there’s also 16-bit floating point (torch.float16 or torch.half) and 64-bit floating point (torch.float64 or torch.double).</p></li>
<li><p>The reason for all of these is to do with precision in computing. Precision is the amount of detail used to describe a number.</p></li>
<li><p>The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.</p></li>
<li><p>This matters in deep learning and numerical computing because you’re making so many operations, the more detail you have to calculate on, the more compute you have to use.</p></li>
<li><p>So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).</p></li>
</ul>
<div id="cell-106" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>float_16_tensor <span class="op">=</span> torch.tensor([<span class="fl">3.0</span>, <span class="fl">6.0</span>, <span class="fl">9.0</span>],</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>                               dtype<span class="op">=</span>torch.float16) <span class="co"># torch.half would also work</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>float_16_tensor.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>torch.float16</code></pre>
</div>
</div>
</section>
<section id="creating-tensors-from-random-numbers" class="level5">
<h5 class="anchored" data-anchor-id="creating-tensors-from-random-numbers">2: Creating Tensors from Random Numbers</h5>
<div id="cell-108" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>a_random_torch <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>) <span class="co"># uniform random distribution numbers between 0 and 1</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a_numpy_rand = np.random.randn(2,3) #numpy random normal distribution</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>(<span class="dv">2</span>,<span class="dv">3</span>)  </span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random_torch)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="co"># print(a_numpy_rand)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0.0461,  0.4024, -1.0115],
        [ 0.2167, -0.6123,  0.5036]])</code></pre>
</div>
</div>
<div id="cell-109" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>a_random_torch <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>) <span class="co"># random normal distribution</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a_numpy_rand = np.random.rand(2,3) </span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random_torch)</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="co"># print(a_numpy_rand)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.7749, 0.8208, 0.2793],
        [0.6817, 0.2837, 0.6567]])</code></pre>
</div>
</div>
</section>
<section id="creating-a-filled-tensor" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-filled-tensor">3: Creating a filled tensor</h3>
<div id="cell-111" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>a_same_scalar <span class="op">=</span> torch.zeros(<span class="dv">10</span>,<span class="dv">5</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_same_scalar)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_same_scalar.size())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]])
torch.Size([10, 5])</code></pre>
</div>
</div>
<div id="cell-112" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>torch.ones(<span class="dv">6</span>, <span class="dv">10</span>) <span class="co"># torch.ones(size=(6, 10)) </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])</code></pre>
</div>
</div>
<div id="cell-113" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>a_zero <span class="op">=</span> torch.zeros(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_zero)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<div id="cell-114" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>a_zero.fill_(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor([[5., 5., 5.],
        [5., 5., 5.]])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Any PyTorch method with an underscore (_) refers to an in­place operation;</p>
</blockquote>
<div id="cell-116" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>a_zero.fill_(<span class="dv">5</span>).size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>torch.Size([2, 3])</code></pre>
</div>
</div>
<section id="creating-and-initializing-a-tensor-from-lists" class="level4">
<h4 class="anchored" data-anchor-id="creating-and-initializing-a-tensor-from-lists">4: Creating and initializing a tensor from lists</h4>
<div id="cell-118" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>a_list <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>a_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
<div id="cell-119" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>a_list <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], </span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>                      [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>a_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>tensor([[1, 2, 3],
        [4, 5, 6]])</code></pre>
</div>
</div>
</section>
<section id="creating-and-initializing-a-tensor-from-numpy-arrays" class="level4">
<h4 class="anchored" data-anchor-id="creating-and-initializing-a-tensor-from-numpy-arrays">5: Creating and initializing a tensor from numpy arrays</h4>
<ul>
<li>The values can either come from a list, as in the preceding example, or from a NumPy array</li>
</ul>
<div id="cell-122" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>numpy_array <span class="op">=</span> np.random.rand(<span class="dv">2</span>, <span class="dv">3</span>) </span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>numpy_array</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>array([[0.31112954, 0.99590158, 0.73157034],
       [0.6366771 , 0.1105546 , 0.84468547]])</code></pre>
</div>
</div>
<div id="cell-123" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(numpy_array)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>numpy.ndarray</code></pre>
</div>
</div>
<div id="cell-124" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>torch_tensor <span class="op">=</span> torch.from_numpy(numpy_array)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>torch_tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([[0.3111, 0.9959, 0.7316],
        [0.6367, 0.1106, 0.8447]], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="cell-125" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>torch_tensor.<span class="bu">type</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>'torch.DoubleTensor'</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>DoubleTensor instead of the default FloatTensor (see the next section). This corresponds with the data type of the NumPy random matrix, a float64,</p>
</blockquote>
<p>You can always convert from PyTorch tensors to Numpy arrays using the numpy function torch.numpy().</p>
</section>
<section id="creating-a-range-and-tensors-like" class="level4">
<h4 class="anchored" data-anchor-id="creating-a-range-and-tensors-like">6: Creating a range and tensors like</h4>
<div id="cell-129" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use torch.arange(), torch.range() is deprecated </span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>zero_to_ten_deprecated <span class="op">=</span> torch.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># Note: this may return an error in the future</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/1h/b7ng0kgj3w78mg7n8k7q7rch0000gn/T/ipykernel_83392/2171007885.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future</code></pre>
</div>
</div>
<div id="cell-130" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a range of values 0 to 10</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>zero_to_ten <span class="op">=</span> torch.arange(start<span class="op">=</span><span class="dv">0</span>, end<span class="op">=</span><span class="dv">10</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>zero_to_ten</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre>
</div>
</div>
</section>
<section id="creating-tensor-of-type-with-the-same-shape-as-another-tensor." class="level4">
<h4 class="anchored" data-anchor-id="creating-tensor-of-type-with-the-same-shape-as-another-tensor.">7:Creating tensor of type with the same shape as another tensor.</h4>
<div id="cell-132" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can also create a tensor of zeros similar to another tensor</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>ten_zeros <span class="op">=</span> torch.zeros_like(<span class="bu">input</span><span class="op">=</span>zero_to_ten) <span class="co"># will have same shape</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>ten_zeros</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</code></pre>
</div>
</div>
<div id="cell-133" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can also create a tensor of zeros similar to another tensor</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>ten_zeros <span class="op">=</span> torch.ones_like(<span class="bu">input</span><span class="op">=</span>zero_to_ten) <span class="co"># will have same shape</span></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>ten_zeros</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])</code></pre>
</div>
</div>
</section>
<section id="dimensions-of-a-tensor-using-the-ndim-attribute" class="level4">
<h4 class="anchored" data-anchor-id="dimensions-of-a-tensor-using-the-ndim-attribute">Dimensions of a tensor using the ndim attribute</h4>
<div id="cell-135" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalar</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>scalar <span class="op">=</span> torch.tensor(<span class="dv">7</span>)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>scalar</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor(7)</code></pre>
</div>
</div>
<div id="cell-136" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>scalar.ndim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>0</code></pre>
</div>
</div>
<div id="cell-137" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalar</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>vector <span class="op">=</span> torch.tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>])</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>vector</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>tensor([1, 2, 3, 4])</code></pre>
</div>
</div>
<div id="cell-138" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>vector.ndim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>1</code></pre>
</div>
</div>
<div id="cell-139" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>MATRIX <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>],</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>                       [<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>]])</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>MATRIX</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor([[1, 2, 3, 4],
        [5, 6, 7, 8]])</code></pre>
</div>
</div>
<div id="cell-140" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>MATRIX.ndim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>2</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>You can tell the number of dimensions a tensor in PyTorch has by the number of square brackets on the outside ([) and you only need to count one side of the brackets.</p>
</blockquote>
<div id="cell-142" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>TENSOR <span class="op">=</span> torch.tensor([[[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>                        [<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">9</span>],</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>                        [<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>]]])</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>TENSOR</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>tensor([[[1, 2, 3],
         [3, 6, 9],
         [2, 4, 5]]])</code></pre>
</div>
</div>
<div id="cell-143" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>TENSOR.ndim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>3</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>In practice, you’ll often see scalars and vectors denoted as lowercase letters such as y or a. And matrices and tensors denoted as uppercase letters such as X or W</p>
</blockquote>
</section>
</section>
<section id="creating-named-tensors" class="level3">
<h3 class="anchored" data-anchor-id="creating-named-tensors">Creating Named Tensors</h3>
<ul>
<li><p>Named Tensors allow users to give explicit names to tensor dimensions.</p></li>
<li><p>In most cases, operations that take dimension parameters will accept dimension names, avoiding the need to track dimensions by position.</p></li>
</ul>
<div id="cell-147" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>torch.zeros(<span class="dv">2</span>, <span class="dv">3</span>, names<span class="op">=</span>(<span class="st">'N'</span>, <span class="st">'C'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/1h/b7ng0kgj3w78mg7n8k7q7rch0000gn/T/ipykernel_83392/697701580.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1654931446436/work/c10/core/TensorImpl.h:1489.)
  torch.zeros(2, 3, names=('N', 'C'))</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.]], names=('N', 'C'))</code></pre>
</div>
</div>
<ul>
<li>Use names to access tensor dimensions.</li>
</ul>
<div id="cell-149" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span> , names<span class="op">=</span>(<span class="st">'N'</span>, <span class="st">'C'</span>, <span class="st">'H'</span>, <span class="st">'W'</span>)) </span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>imgs.names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>('N', 'C', 'H', 'W')</code></pre>
</div>
</div>
<div id="cell-150" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>imgs.names[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>'N'</code></pre>
</div>
</div>
<div id="cell-151" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>imgs.names[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>'C'</code></pre>
</div>
</div>
</section>
</section>
<section id="indexing-tensors" class="level2">
<h2 class="anchored" data-anchor-id="indexing-tensors">Indexing tensors</h2>
<p>Indexing a tensor is similar to indexing a list.</p>
<blockquote class="blockquote">
<p>List indexing:</p>
</blockquote>
<div id="cell-155" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>some_list <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">6</span>))</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>some_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>[0, 1, 2, 3, 4, 5]</code></pre>
</div>
</div>
<div id="cell-156" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>some_list[<span class="dv">1</span>:<span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>[1, 2, 3]</code></pre>
</div>
</div>
<div id="cell-157" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>some_list[<span class="dv">1</span>:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>[1, 2, 3, 4, 5]</code></pre>
</div>
</div>
<div id="cell-158" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>some_list[<span class="dv">1</span>:<span class="dv">4</span>:<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>[1, 3]</code></pre>
</div>
</div>
<div id="cell-159" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>some_list[:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>[0, 1, 2, 3, 4, 5]</code></pre>
</div>
</div>
<div id="cell-160" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(some_list[:<span class="dv">4</span>])</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(some_list[:<span class="op">-</span><span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0, 1, 2, 3]
[0, 1, 2, 3, 4]</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Pytorch tensor indexing:</p>
</blockquote>
<div id="cell-162" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>torch_list <span class="op">=</span> torch.tensor(some_list)</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>torch_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>tensor([0, 1, 2, 3, 4, 5])</code></pre>
</div>
</div>
<div id="cell-163" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>torch_list[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>tensor(0)</code></pre>
</div>
</div>
<div id="cell-164" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>torch_list[<span class="dv">1</span>:<span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
</section>
<section id="transposing-tensors" class="level2">
<h2 class="anchored" data-anchor-id="transposing-tensors">Transposing Tensors</h2>
<p>Transposing 2D tensors is a simple operation using <code>t</code></p>
<div id="cell-167" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>points <span class="op">=</span> torch.tensor([[<span class="fl">4.0</span>, <span class="fl">1.0</span>], [<span class="fl">5.0</span>, <span class="fl">3.0</span>], [<span class="fl">2.0</span>, <span class="fl">1.0</span>]])</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>points</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>tensor([[4., 1.],
        [5., 3.],
        [2., 1.]])</code></pre>
</div>
</div>
<div id="cell-168" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>points_t <span class="op">=</span> points.t()</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>points_t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>tensor([[4., 5., 2.],
        [1., 3., 1.]])</code></pre>
</div>
</div>
<p>You can also transpose 3D and higher tensors using the <code>transpose</code> method by specifying the two dimensions along which transposing (flipping shape and stride) should occur:</p>
<div id="cell-170" class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>some_t <span class="op">=</span> torch.ones(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>transpose_t <span class="op">=</span> some_t.transpose(<span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>some_t.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>torch.Size([3, 4, 5])</code></pre>
</div>
</div>
</section>
<section id="manipulating-tensors-tensor-operations" class="level2">
<h2 class="anchored" data-anchor-id="manipulating-tensors-tensor-operations">Manipulating tensors (tensor operations)</h2>
<ul>
<li><p>In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.</p></li>
<li><p>A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.</p></li>
<li><p>After you have created your tensors, you can operate on them like you would do with traditional programming language types, like +, ­, *, /.</p></li>
</ul>
<blockquote class="blockquote">
<p>Addition: torch.add(tensor1, tensor2)</p>
</blockquote>
<div id="cell-174" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor of values and add a number to it</span></span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">+</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>tensor([11, 12, 13])</code></pre>
</div>
</div>
<div id="cell-175" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiply it by 10</span></span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">*</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>tensor([10, 20, 30])</code></pre>
</div>
</div>
<div id="cell-176" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Subtract and reassign</span></span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> tensor <span class="op">-</span> <span class="dv">10</span></span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>tensor([-9, -8, -7])</code></pre>
</div>
</div>
<div id="cell-177" class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">4</span>)</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>tensor([-0.4790,  0.8539, -0.2285,  0.3081])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>PyTorch also has a bunch of built-in functions like torch.mul() (short for multiplcation) and torch.add() to perform basic operations.</p>
</blockquote>
<div id="cell-179" class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can also use torch functions</span></span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>torch.multiply(tensor, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>tensor([10, 20, 30])</code></pre>
</div>
</div>
<div id="cell-180" class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a>torch.add(tensor, <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>tensor([21, 22, 23])</code></pre>
</div>
</div>
<div id="cell-181" class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>torch.div(tensor, <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>tensor([0.0500, 0.1000, 0.1500])</code></pre>
</div>
</div>
<div id="cell-182" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>torch.div(tensor, <span class="dv">20</span>, rounding_mode<span class="op">=</span><span class="st">'trunc'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>tensor([0, 0, 0])</code></pre>
</div>
</div>
<div id="cell-183" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>torch.div(tensor, <span class="dv">20</span>, rounding_mode<span class="op">=</span><span class="st">'floor'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>tensor([0, 0, 0])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Sum: torch.sum(tensor)</p>
</blockquote>
<div id="cell-185" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>tensor([[ 1.1171,  0.1585, -0.8696]])</code></pre>
</div>
</div>
<div id="cell-186" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>tensor(0.4060)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>More operations can be found in the <a href="https://pytorch.org/docs/stable/torch.html#torch-tensor-operations">Tensor Operations</a> section.</p>
</blockquote>
<section id="matrix-multiplication-is-all-you-need" class="level3">
<h3 class="anchored" data-anchor-id="matrix-multiplication-is-all-you-need">Matrix multiplication (is all you need)</h3>
<ul>
<li><p>One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.</p></li>
<li><p>PyTorch implements matrix multiplication functionality in the torch.matmul() method.</p></li>
<li><p>The main two rules for matrix multiplication to remember are:</p></li>
</ul>
<p>The inner dimensions must match:</p>
<ul>
<li>(3, 2) @ (3, 2) won’t work</li>
<li>(2, 3) @ (3, 2) will work</li>
<li>(3, 2) @ (2, 3) will work</li>
</ul>
<p>The resulting matrix has the shape of the outer dimensions:</p>
<ul>
<li>(2, 3) @ (3, 2) -&gt; (2, 2)</li>
<li>(3, 2) @ (2, 3) -&gt; (3, 3)</li>
</ul>
<p>Note: “@” in Python is the symbol for matrix multiplication.</p>
<p>More information about matrix multiplication can be found in the <a href="https://pytorch.org/docs/stable/torch.html#torch-matmul">Matrix Multiplication</a> section.</p>
<div id="cell-192" class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>tensor1 <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>tensor2 <span class="op">=</span> torch.randn(<span class="dv">4</span>)</span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor1.shape)</span>
<span id="cb165-5"><a href="#cb165-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor2.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 4])
torch.Size([4])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Can we multiply these tensors?</p>
</blockquote>
<div id="cell-194" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> torch.matmul(tensor1, tensor2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-195" class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>tensor([ 9.1468,  4.9503, -1.1270])</code></pre>
</div>
</div>
<div id="cell-196" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>result.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>torch.Size([3])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>The difference between element-wise multiplication (multiply) and matrix multiplication (matmul) is the addition of values.</p>
</blockquote>
<ul>
<li><p>matmul: matrix multiplication</p></li>
<li><p>multiply: element-wise multiplication</p></li>
</ul>
<div id="cell-198" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>torch.Size([3])</code></pre>
</div>
</div>
<div id="cell-199" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Element-wise matrix mutlication</span></span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">*</span> tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor([1, 4, 9])</code></pre>
</div>
</div>
<div id="cell-200" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix multiplication</span></span>
<span id="cb176-2"><a href="#cb176-2" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor, tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>tensor(14)</code></pre>
</div>
</div>
<div id="cell-201" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can also use the "@" symbol for matrix multiplication, though not recommended</span></span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">@</span> tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>tensor(14)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>One of the most common errors in deep learning (shape errors)</p>
</blockquote>
<div id="cell-203" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Shapes need to be in the right way  </span></span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>tensor_A <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">3</span>, <span class="dv">4</span>],</span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">5</span>, <span class="dv">6</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb180-5"><a href="#cb180-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-6"><a href="#cb180-6" aria-hidden="true" tabindex="-1"></a>tensor_B <span class="op">=</span> torch.tensor([[<span class="dv">7</span>, <span class="dv">10</span>],</span>
<span id="cb180-7"><a href="#cb180-7" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">8</span>, <span class="dv">11</span>], </span>
<span id="cb180-8"><a href="#cb180-8" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">9</span>, <span class="dv">12</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb180-9"><a href="#cb180-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-10"><a href="#cb180-10" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor_A, tensor_B) <span class="co"># (this will error)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)</code></pre>
</div>
</div>
<div id="cell-204" class="cell">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_A.shape)</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_B.shape)</span>
<span id="cb182-3"><a href="#cb182-3" aria-hidden="true" tabindex="-1"></a><span class="co">#The shape of the tensor is not compatible with the shape of the matrix.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 2])
torch.Size([3, 2])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Solution !!! make matrix multiplication work between tensor_A and tensor_B by making their inner dimensions match using Transpose() operation.</p>
</blockquote>
<div id="cell-206" class="cell">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View tensor_A and tensor_B</span></span>
<span id="cb184-2"><a href="#cb184-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_A)</span>
<span id="cb184-3"><a href="#cb184-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_B)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 2.],
        [3., 4.],
        [5., 6.]])
tensor([[ 7., 10.],
        [ 8., 11.],
        [ 9., 12.]])</code></pre>
</div>
</div>
<div id="cell-207" class="cell">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View tensor_A and tensor_B.T</span></span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_A)</span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_B.T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 2.],
        [3., 4.],
        [5., 6.]])
tensor([[ 7.,  8.,  9.],
        [10., 11., 12.]])</code></pre>
</div>
</div>
<div id="cell-208" class="cell">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The operation works when tensor_B is transposed</span></span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original shapes: tensor_A = </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, tensor_B = </span><span class="sc">{</span>tensor_B<span class="sc">.</span>shape<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New shapes: tensor_A = </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (same as above), tensor_B.T = </span><span class="sc">{</span>tensor_B<span class="sc">.</span>T<span class="sc">.</span>shape<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb188-4"><a href="#cb188-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Multiplying: </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> * </span><span class="sc">{</span>tensor_B<span class="sc">.</span>T<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> &lt;- inner dimensions match</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb188-5"><a href="#cb188-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Output:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb188-6"><a href="#cb188-6" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> torch.matmul(tensor_A, tensor_B.T)</span>
<span id="cb188-7"><a href="#cb188-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output) </span>
<span id="cb188-8"><a href="#cb188-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Output shape: </span><span class="sc">{</span>output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])

New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])

Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) &lt;- inner dimensions match

Output:

tensor([[ 27.,  30.,  33.],
        [ 61.,  68.,  75.],
        [ 95., 106., 117.]])

Output shape: torch.Size([3, 3])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>You can also use torch.mm() which is a short for torch.matmul().</p>
</blockquote>
<div id="cell-210" class="cell">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.mm is a shortcut for matmul</span></span>
<span id="cb190-2"><a href="#cb190-2" aria-hidden="true" tabindex="-1"></a>torch.mm(tensor_A, tensor_B.T)  <span class="co"># same as: torch.matmul(tensor_A, tensor_B.T)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="363">
<pre><code>tensor([[ 27.,  30.,  33.],
        [ 61.,  68.,  75.],
        [ 95., 106., 117.]])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: A matrix multiplication like this is also referred to as the dot product of two matrices. Neural networks are full of matrix multiplications and dot products.</p>
</blockquote>
<p>For example, <a href="https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html"><code>torch.nn.Linear()</code></a> module (we’ll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input <code>x</code> and a weights matrix <code>A</code>.</p>
<p><span class="math display">\[
y = x\cdot{A^T} + b
\]</span></p>
<section id="tensor-view-operation" class="level4">
<h4 class="anchored" data-anchor-id="tensor-view-operation">Tensor View Operation</h4>
<blockquote class="blockquote">
<p>Returns a new tensor with the same data as the self tensor but of a different shape.</p>
</blockquote>
<div id="cell-215" class="cell">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="374">
<pre><code>tensor([[ 0.2329, -1.1014, -1.2473, -0.7485],
        [-0.9792,  0.8285, -0.2501,  0.1602],
        [ 0.7295, -0.4441,  0.8214, -0.6015],
        [ 0.9069,  1.5691, -0.1108, -0.2573]])</code></pre>
</div>
</div>
<div id="cell-216" class="cell">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>x.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="375">
<pre><code>torch.Size([4, 4])</code></pre>
</div>
</div>
<div id="cell-217" class="cell">
<div class="sourceCode cell-code" id="cb196"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x.view(<span class="dv">16</span>)</span>
<span id="cb196-2"><a href="#cb196-2" aria-hidden="true" tabindex="-1"></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="377">
<pre><code>tensor([ 0.2329, -1.1014, -1.2473, -0.7485, -0.9792,  0.8285, -0.2501,  0.1602,
         0.7295, -0.4441,  0.8214, -0.6015,  0.9069,  1.5691, -0.1108, -0.2573])</code></pre>
</div>
</div>
<div id="cell-218" class="cell">
<div class="sourceCode cell-code" id="cb198"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>y.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="378">
<pre><code>torch.Size([16])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Using -1 in the shape argument will automatically infer the correct size of the dimension.</p>
</blockquote>
<div id="cell-220" class="cell">
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span>)  <span class="co"># the size -1 is inferred from other dimensions</span></span>
<span id="cb200-2"><a href="#cb200-2" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="379">
<pre><code>tensor([[ 0.2329, -1.1014, -1.2473, -0.7485, -0.9792,  0.8285, -0.2501,  0.1602],
        [ 0.7295, -0.4441,  0.8214, -0.6015,  0.9069,  1.5691, -0.1108, -0.2573]])</code></pre>
</div>
</div>
<div id="cell-221" class="cell">
<div class="sourceCode cell-code" id="cb202"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb202-1"><a href="#cb202-1" aria-hidden="true" tabindex="-1"></a>z.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="380">
<pre><code>torch.Size([2, 8])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>View Does not change tensor layout in memory</p>
</blockquote>
<p>Transpose() operation is used to change the tensor layout in memory.</p>
<div id="cell-224" class="cell">
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb204-2"><a href="#cb204-2" aria-hidden="true" tabindex="-1"></a>a.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="381">
<pre><code>torch.Size([1, 2, 3, 4])</code></pre>
</div>
</div>
<div id="cell-225" class="cell">
<div class="sourceCode cell-code" id="cb206"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a.transpose(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># Swaps 2nd and 3rd dimension</span></span>
<span id="cb206-2"><a href="#cb206-2" aria-hidden="true" tabindex="-1"></a>b.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="382">
<pre><code>torch.Size([1, 3, 2, 4])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Tensor API provide group of operation on working with Tensors</p>
</blockquote>
</section>
</section>
</section>
<section id="tensors-and-computational-graphs" class="level2">
<h2 class="anchored" data-anchor-id="tensors-and-computational-graphs">Tensors and Computational Graphs</h2>
<ul>
<li><p>Tensor.requires_grad is a boolean flag that indicates whether the tensor requires gradient.</p></li>
<li><p>When you create a tensor with requires_grad=True, you are requiring PyTorch to manage bookkeeping information that computes gradients.</p></li>
<li><p>First, PyTorch will keep track of the values of the forward pass. Then, at the end of the computations, a single scalar is used to compute a backward pass.</p></li>
<li><p>The backward pass is initiated by using the backward() method on a tensor resulting from the evaluation of a loss function. The backward pass computes a gradient value for a tensor object that participated in the forward pass.</p></li>
</ul>
<div id="cell-229" class="cell">
<div class="sourceCode cell-code" id="cb208"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb208-1"><a href="#cb208-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb208-2"><a href="#cb208-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>) </span>
<span id="cb208-3"><a href="#cb208-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad <span class="kw">is</span> <span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div id="cell-230" class="cell">
<div class="sourceCode cell-code" id="cb210"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">5</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb210-2"><a href="#cb210-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x.<span class="bu">pow</span>(<span class="dv">2</span>)</span>
<span id="cb210-3"><a href="#cb210-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.equal(y.grad_fn._saved_self))  <span class="co"># True</span></span>
<span id="cb210-4"><a href="#cb210-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x <span class="kw">is</span> y.grad_fn._saved_self)  <span class="co"># True</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True
True</code></pre>
</div>
</div>
<ul>
<li>let’s run through a few ways to aggregate them (go from more values to less values).</li>
</ul>
<div id="cell-232" class="cell">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor</span></span>
<span id="cb212-2"><a href="#cb212-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb212-3"><a href="#cb212-3" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="385">
<pre><code>tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])</code></pre>
</div>
</div>
<div id="cell-233" class="cell">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Minimum: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb214-2"><a href="#cb214-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Maximum: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb214-3"><a href="#cb214-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">type</span>(torch.float32)<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>) <span class="co"># won't work without float datatype</span></span>
<span id="cb214-4"><a href="#cb214-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sum: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Minimum: 0
Maximum: 90
Mean: 45.0
Sum: 450</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: You may find some methods such as torch.mean() require tensors to be in torch.float32 (the most common) or another specific datatype, otherwise the operation will fail.</p>
</blockquote>
<div id="cell-235" class="cell">
<div class="sourceCode cell-code" id="cb216"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean: </span><span class="sc">{</span>x<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>) <span class="co"># this will error</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long</code></pre>
</div>
</div>
<p>You can also do the same as above with torch methods.</p>
<div id="cell-237" class="cell">
<div class="sourceCode cell-code" id="cb218"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.<span class="bu">max</span>(x))</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-3"><a href="#cb218-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.<span class="bu">min</span>(x))</span>
<span id="cb218-4"><a href="#cb218-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-5"><a href="#cb218-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.mean(x.<span class="bu">type</span>(torch.float32)))</span>
<span id="cb218-6"><a href="#cb218-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-7"><a href="#cb218-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.<span class="bu">sum</span>(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(90)
tensor(0)
tensor(45.)
tensor(450)</code></pre>
</div>
</div>
</section>
<section id="positional-minmax" class="level2">
<h2 class="anchored" data-anchor-id="positional-minmax">Positional min/max</h2>
<ul>
<li><p>You can also find the index of a tensor where the max or minimum occurs with torch.argmax() and torch.argmin() respectively.</p></li>
<li><p>This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we’ll see this in a later section when using the softmax activation function).</p></li>
</ul>
<div id="cell-240" class="cell">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor</span></span>
<span id="cb220-2"><a href="#cb220-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.arange(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb220-3"><a href="#cb220-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor: </span><span class="sc">{</span>tensor<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb220-4"><a href="#cb220-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-5"><a href="#cb220-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Returns index of max and min values</span></span>
<span id="cb220-6"><a href="#cb220-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Index where max value occurs: </span><span class="sc">{</span>tensor<span class="sc">.</span>argmax()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb220-7"><a href="#cb220-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Index where min value occurs: </span><span class="sc">{</span>tensor<span class="sc">.</span>argmin()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])
Index where max value occurs: 8
Index where min value occurs: 0</code></pre>
</div>
</div>
</section>
<section id="change-tensor-datatype" class="level2">
<h2 class="anchored" data-anchor-id="change-tensor-datatype">Change tensor datatype</h2>
<ul>
<li><p>A common issue with deep learning operations is having your tensors in different datatypes.</p></li>
<li><p>If one tensor is in torch.float64 and another is in torch.float32, you might run into some errors.</p></li>
<li><p>But there’s a fix.</p></li>
<li><p>You can change the datatypes of tensors using torch.Tensor.type(dtype=None) where the dtype parameter is the datatype you’d like to use</p></li>
</ul>
<div id="cell-243" class="cell">
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor and check its datatype</span></span>
<span id="cb222-2"><a href="#cb222-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.arange(<span class="fl">10.</span>, <span class="fl">100.</span>, <span class="fl">10.</span>)</span>
<span id="cb222-3"><a href="#cb222-3" aria-hidden="true" tabindex="-1"></a>tensor.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="398">
<pre><code>torch.float32</code></pre>
</div>
</div>
<div id="cell-244" class="cell">
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a float16 tensor</span></span>
<span id="cb224-2"><a href="#cb224-2" aria-hidden="true" tabindex="-1"></a>tensor_float16 <span class="op">=</span> tensor.<span class="bu">type</span>(torch.float16)</span>
<span id="cb224-3"><a href="#cb224-3" aria-hidden="true" tabindex="-1"></a>tensor_float16</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="399">
<pre><code>tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)</code></pre>
</div>
</div>
<div id="cell-245" class="cell">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a int8 tensor</span></span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a>tensor_int8 <span class="op">=</span> tensor.<span class="bu">type</span>(torch.int8)</span>
<span id="cb226-3"><a href="#cb226-3" aria-hidden="true" tabindex="-1"></a>tensor_int8</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="400">
<pre><code>tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)</code></pre>
</div>
</div>
<section id="reshaping-stacking-squeezing-and-unsqueezing" class="level3">
<h3 class="anchored" data-anchor-id="reshaping-stacking-squeezing-and-unsqueezing">Reshaping, stacking, squeezing and unsqueezing</h3>
<ul>
<li>Often times you’ll want to reshape or change the dimensions of your tensors without actually changing the values inside them.</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>Method</th>
<th>One-line description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape"><code>torch.reshape(input, shape)</code></a></td>
<td>Reshapes <code>input</code> to <code>shape</code> (if compatible), can also use <code>torch.Tensor.reshape()</code>.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.Tensor.view.html"><code>torch.Tensor.view(shape)</code></a></td>
<td>Returns a view of the original tensor in a different <code>shape</code> but shares the same data as the original tensor.</td>
</tr>
<tr class="odd">
<td><a href="https://pytorch.org/docs/1.9.1/generated/torch.stack.html"><code>torch.stack(tensors, dim=0)</code></a></td>
<td>Concatenates a sequence of <code>tensors</code> along a new dimension (<code>dim</code>), all <code>tensors</code> must be same size.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.squeeze.html"><code>torch.squeeze(input)</code></a></td>
<td>Squeezes <code>input</code> to remove all the dimenions with value <code>1</code>.</td>
</tr>
<tr class="odd">
<td><a href="https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html"><code>torch.unsqueeze(input, dim)</code></a></td>
<td>Returns <code>input</code> with a dimension value of <code>1</code> added at <code>dim</code>.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.permute.html"><code>torch.permute(input, dims)</code></a></td>
<td>Returns a <em>view</em> of the original <code>input</code> with its dimensions permuted (rearranged) to <code>dims</code>.</td>
</tr>
</tbody>
</table>
<p>Why do any of these?</p>
<p>Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you’ve got shape mismatches, you’ll run into errors. These methods help you make the right elements of your tensors are mixing with the right elements of other tensors.</p>
<p>Let’s try them out.</p>
<p>First, we’ll create a tensor.</p>
<section id="reshape-and-view" class="level5">
<h5 class="anchored" data-anchor-id="reshape-and-view">Reshape and View</h5>
<div id="cell-250" class="cell">
<div class="sourceCode cell-code" id="cb228"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor</span></span>
<span id="cb228-2"><a href="#cb228-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb228-3"><a href="#cb228-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="fl">1.</span>, <span class="fl">8.</span>)</span>
<span id="cb228-4"><a href="#cb228-4" aria-hidden="true" tabindex="-1"></a>x, x.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="401">
<pre><code>(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))</code></pre>
</div>
</div>
<p>Now let’s add an extra dimension with torch.reshape().</p>
<div id="cell-252" class="cell">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add an extra dimension</span></span>
<span id="cb230-2"><a href="#cb230-2" aria-hidden="true" tabindex="-1"></a>x_reshaped <span class="op">=</span> x.reshape(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb230-3"><a href="#cb230-3" aria-hidden="true" tabindex="-1"></a>x_reshaped, x_reshaped.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="403">
<pre><code>(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))</code></pre>
</div>
</div>
<p>We can also change the view with torch.view().</p>
<div id="cell-254" class="cell">
<div class="sourceCode cell-code" id="cb232"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change view (keeps same data as original but changes view)</span></span>
<span id="cb232-2"><a href="#cb232-2" aria-hidden="true" tabindex="-1"></a><span class="co"># See more: https://stackoverflow.com/a/54507446/7900723</span></span>
<span id="cb232-3"><a href="#cb232-3" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x.view(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb232-4"><a href="#cb232-4" aria-hidden="true" tabindex="-1"></a>z, z.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="404">
<pre><code>(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))</code></pre>
</div>
</div>
</section>
<section id="torch.view-vs-torch.reshape" class="level5">
<h5 class="anchored" data-anchor-id="torch.view-vs-torch.reshape">Torch.View vs Torch.Reshape</h5>
<ul>
<li><p>Both view() and reshape() can be used to change the size or shape of tensors. But they are slightly different.</p></li>
<li><p>The view() has existed for a long time. It will return a tensor with the new shape. The returned tensor shares the underling data with the original tensor. If you change the tensor value in the returned tensor, the corresponding value in the viewed tensor also changes.</p></li>
<li><p>Tensor.reshape() is more robust. It will work on any tensor, while Tensor.view() works only on tensor t where t.is_contiguous()==True.</p></li>
</ul>
<div id="cell-256" class="cell">
<div class="sourceCode cell-code" id="cb234"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb234-1"><a href="#cb234-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.zeros(<span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb234-2"><a href="#cb234-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> z.view(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb234-3"><a href="#cb234-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb234-4"><a href="#cb234-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z)</span>
<span id="cb234-5"><a href="#cb234-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0., 0.],
        [0., 0.],
        [0., 0.]])
tensor([[0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<div id="cell-257" class="cell">
<div class="sourceCode cell-code" id="cb236"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a>z.fill_(<span class="dv">1</span>)</span>
<span id="cb236-2"><a href="#cb236-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb236-3"><a href="#cb236-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb236-4"><a href="#cb236-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z)</span>
<span id="cb236-5"><a href="#cb236-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 1.],
        [1., 1.],
        [1., 1.]])
tensor([[1., 1., 1.],
        [1., 1., 1.]])</code></pre>
</div>
</div>
<p>According to <a href="https://pytorch.org/docs/master/generated/torch.reshape.html#torch.reshape">documentation</a></p>
<blockquote class="blockquote">
<p>Reshape() Returns a tensor with the same data and number of elements as input, but with the specified shape. When possible, the returned tensor will be a view of input. Otherwise, it will be a copy. Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs.&nbsp;viewing behavior.</p>
</blockquote>
<div id="cell-260" class="cell">
<div class="sourceCode cell-code" id="cb238"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="fl">4.</span>)</span>
<span id="cb238-2"><a href="#cb238-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-3"><a href="#cb238-3" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.reshape(a, (<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb238-4"><a href="#cb238-4" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="437">
<pre><code>tensor([[0., 1.],
        [2., 3.]])</code></pre>
</div>
</div>
<div id="cell-261" class="cell">
<div class="sourceCode cell-code" id="cb240"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a>a.fill_(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="438">
<pre><code>tensor([2., 2., 2., 2.])</code></pre>
</div>
</div>
<div id="cell-262" class="cell">
<div class="sourceCode cell-code" id="cb242"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb242-1"><a href="#cb242-1" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="436">
<pre><code>tensor([[2., 2.],
        [2., 2.]])</code></pre>
</div>
</div>
<p>More about reshape vs view <a href="https://discuss.pytorch.org/t/equivalent-of-np-reshape-in-pytorch/144/16">here</a> , <a href="https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/">here</a></p>
</section>
</section>
<section id="stack-tensor" class="level3">
<h3 class="anchored" data-anchor-id="stack-tensor">Stack Tensor</h3>
<ul>
<li><p>If we wanted to stack our new tensor on top of itself five times, we could do so with torch.stack().</p></li>
<li><p>Concatenates a sequence of tensors along a new dimension.</p></li>
<li><p>All tensors need to be of the same size.</p></li>
</ul>
<div id="cell-266" class="cell">
<div class="sourceCode cell-code" id="cb244"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a><span class="co"># creating tensors</span></span>
<span id="cb244-2"><a href="#cb244-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.</span>,<span class="fl">3.</span>,<span class="fl">6.</span>,<span class="fl">10.</span>])</span>
<span id="cb244-3"><a href="#cb244-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor([<span class="fl">2.</span>,<span class="fl">7.</span>,<span class="fl">9.</span>,<span class="fl">13.</span>])</span>
<span id="cb244-4"><a href="#cb244-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb244-5"><a href="#cb244-5" aria-hidden="true" tabindex="-1"></a><span class="co"># printing above created tensors</span></span>
<span id="cb244-6"><a href="#cb244-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tensor x:"</span>, x)</span>
<span id="cb244-7"><a href="#cb244-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tensor y:"</span>, y)</span>
<span id="cb244-8"><a href="#cb244-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb244-9"><a href="#cb244-9" aria-hidden="true" tabindex="-1"></a><span class="co"># join above tensor using "torch.stack()"</span></span>
<span id="cb244-10"><a href="#cb244-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"join tensors:"</span>)</span>
<span id="cb244-11"><a href="#cb244-11" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.stack((x,y))</span>
<span id="cb244-12"><a href="#cb244-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb244-13"><a href="#cb244-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print final tensor after join</span></span>
<span id="cb244-14"><a href="#cb244-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t)</span>
<span id="cb244-15"><a href="#cb244-15" aria-hidden="true" tabindex="-1"></a>  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor x: tensor([ 1.,  3.,  6., 10.])
Tensor y: tensor([ 2.,  7.,  9., 13.])
join tensors:
tensor([[ 1.,  3.,  6., 10.],
        [ 2.,  7.,  9., 13.]])</code></pre>
</div>
</div>
<div id="cell-267" class="cell">
<div class="sourceCode cell-code" id="cb246"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"join tensors dimension 0:"</span>)</span>
<span id="cb246-2"><a href="#cb246-2" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.stack((x,y), dim <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb246-3"><a href="#cb246-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>join tensors dimension 0:
tensor([[ 1.,  3.,  6., 10.],
        [ 2.,  7.,  9., 13.]])</code></pre>
</div>
</div>
<div id="cell-268" class="cell">
<div class="sourceCode cell-code" id="cb248"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"join tensors dimension 1:"</span>)</span>
<span id="cb248-2"><a href="#cb248-2" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.stack((x,y), dim <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb248-3"><a href="#cb248-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>join tensors dimension 1:
tensor([[ 1.,  2.],
        [ 3.,  7.],
        [ 6.,  9.],
        [10., 13.]])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>When dim =0 the tensors are stacked increasing the number of rows. When dim =1 the tensors are transposed and stacked along the column.</p>
</blockquote>
<div id="cell-270" class="cell">
<div class="sourceCode cell-code" id="cb250"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack tensors on top of each other</span></span>
<span id="cb250-2"><a href="#cb250-2" aria-hidden="true" tabindex="-1"></a>torch.stack((x,y), dim <span class="op">=</span> <span class="dv">1</span>).size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="467">
<pre><code>torch.Size([4, 2])</code></pre>
</div>
</div>
</section>
<section id="adding-and-removinga-single-dimension-squeeze-and-unsqueeze" class="level3">
<h3 class="anchored" data-anchor-id="adding-and-removinga-single-dimension-squeeze-and-unsqueeze">Adding and Removinga single dimension ( Squeeze and Unsqueeze))</h3>
<ul>
<li>Simply put, unsqueeze() “adds” a superficial 1 dimension to tensor (at the specified dimension), while squeeze removes all superficial 1 dimensions from tensor.</li>
</ul>
<div id="cell-273" class="cell">
<div class="sourceCode cell-code" id="cb252"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>])</span>
<span id="cb252-2"><a href="#cb252-2" aria-hidden="true" tabindex="-1"></a>tensor.shape <span class="co"># torch.Size([5])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="476">
<pre><code>torch.Size([5])</code></pre>
</div>
</div>
<div id="cell-274" class="cell">
<div class="sourceCode cell-code" id="cb254"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb254-1"><a href="#cb254-1" aria-hidden="true" tabindex="-1"></a>tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>).shape <span class="co"># [1, 5]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="477">
<pre><code>torch.Size([1, 5])</code></pre>
</div>
</div>
<div id="cell-275" class="cell">
<div class="sourceCode cell-code" id="cb256"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a>tensor.unsqueeze(dim<span class="op">=</span><span class="dv">1</span>).shape <span class="co"># [5, 1]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="478">
<pre><code>torch.Size([5, 1])</code></pre>
</div>
</div>
<p>It is useful for providing single sample to the network (which requires first dimension to be batch), for images it would be:</p>
<div id="cell-277" class="cell">
<div class="sourceCode cell-code" id="cb258"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb258-1"><a href="#cb258-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 channels, 32 width, 32 height</span></span>
<span id="cb258-2"><a href="#cb258-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb258-3"><a href="#cb258-3" aria-hidden="true" tabindex="-1"></a>tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="473">
<pre><code>torch.Size([3, 32, 32])</code></pre>
</div>
</div>
<div id="cell-278" class="cell">
<div class="sourceCode cell-code" id="cb260"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb260-1"><a href="#cb260-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1 batch, 3 channels, 32 width, 32 height</span></span>
<span id="cb260-2"><a href="#cb260-2" aria-hidden="true" tabindex="-1"></a>tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="474">
<pre><code>torch.Size([1, 3, 32, 32])</code></pre>
</div>
</div>
<div id="cell-279" class="cell">
<div class="sourceCode cell-code" id="cb262"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a>tensor.unsqueeze(dim<span class="op">=</span><span class="dv">1</span>).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="475">
<pre><code>torch.Size([3, 1, 32, 32])</code></pre>
</div>
</div>
<ul>
<li>Squeeze() removes the dimension of size 1 from the tensor.</li>
</ul>
<div id="cell-281" class="cell">
<div class="sourceCode cell-code" id="cb264"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb264-1"><a href="#cb264-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 channels, 32 width, 32 height</span></span>
<span id="cb264-2"><a href="#cb264-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb264-3"><a href="#cb264-3" aria-hidden="true" tabindex="-1"></a>squeezed_tensor <span class="op">=</span> tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb264-4"><a href="#cb264-4" aria-hidden="true" tabindex="-1"></a>squeezed_tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="493">
<pre><code>torch.Size([1, 3, 32, 32])</code></pre>
</div>
</div>
<div id="cell-282" class="cell">
<div class="sourceCode cell-code" id="cb266"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a>squeezed_tensor.squeeze().shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="497">
<pre><code>torch.Size([3, 32, 32])</code></pre>
</div>
</div>
</section>
<section id="permute-tensor" class="level3">
<h3 class="anchored" data-anchor-id="permute-tensor">Permute Tensor</h3>
<ul>
<li>You can also rearrange the order of axes values with torch.permute(input, dims), where the input gets turned into a view with new dims.</li>
</ul>
<div id="cell-285" class="cell">
<div class="sourceCode cell-code" id="cb268"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb268-1"><a href="#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create tensor with specific shape</span></span>
<span id="cb268-2"><a href="#cb268-2" aria-hidden="true" tabindex="-1"></a>x_original <span class="op">=</span> torch.rand(size<span class="op">=</span>(<span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>))</span>
<span id="cb268-3"><a href="#cb268-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb268-4"><a href="#cb268-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Permute the original tensor to rearrange the axis order</span></span>
<span id="cb268-5"><a href="#cb268-5" aria-hidden="true" tabindex="-1"></a>x_permuted <span class="op">=</span> x_original.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># shifts axis 0-&gt;1, 1-&gt;2, 2-&gt;0</span></span>
<span id="cb268-6"><a href="#cb268-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb268-7"><a href="#cb268-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Previous shape: </span><span class="sc">{</span>x_original<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb268-8"><a href="#cb268-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New shape: </span><span class="sc">{</span>x_permuted<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Previous shape: torch.Size([224, 224, 3])
New shape: torch.Size([3, 224, 224])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: Because permuting returns a view (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original.</p>
</blockquote>
</section>
</section>
<section id="indexing-selecting-data-from-tensors" class="level2">
<h2 class="anchored" data-anchor-id="indexing-selecting-data-from-tensors">Indexing (selecting data from tensors)</h2>
<ul>
<li><p>Indexing allow us to select data from tensors(e.g, select the first row of a tensor).</p></li>
<li><p>Indexing a Pytorch tensor is similar to that of a Python list. The pytorch tensor indexing is 0 based, i.e, the first element of the array has index 0.</p></li>
<li><p>Syntax : tensor_name[index]</p></li>
</ul>
<div id="cell-289" class="cell">
<div class="sourceCode cell-code" id="cb270"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb270-1"><a href="#cb270-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">9</span>])</span>
<span id="cb270-2"><a href="#cb270-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb270-3"><a href="#cb270-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">0</span>])</span>
<span id="cb270-4"><a href="#cb270-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(2)
tensor(7)</code></pre>
</div>
</div>
<p>Indexing Range : tensor_name[start_index : end_index]</p>
<div id="cell-291" class="cell">
<div class="sourceCode cell-code" id="cb272"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">9</span>])</span>
<span id="cb272-2"><a href="#cb272-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb272-3"><a href="#cb272-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">1</span> : <span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([4, 1, 7, 0])</code></pre>
</div>
</div>
<div id="cell-292" class="cell">
<div class="sourceCode cell-code" id="cb274"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">9</span>])</span>
<span id="cb274-2"><a href="#cb274-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">2</span> : ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1, 7, 0, 9])</code></pre>
</div>
</div>
<div id="cell-293" class="cell">
<div class="sourceCode cell-code" id="cb276"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">3</span>, <span class="dv">8</span>, <span class="dv">4</span>]])</span>
<span id="cb276-2"><a href="#cb276-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-3"><a href="#cb276-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">1</span>])</span>
<span id="cb276-4"><a href="#cb276-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([3, 8, 4])
tensor([1, 2, 1])</code></pre>
</div>
</div>
<div id="cell-294" class="cell">
<div class="sourceCode cell-code" id="cb278"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">3</span>, <span class="dv">8</span>, <span class="dv">4</span>]])</span>
<span id="cb278-2"><a href="#cb278-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb278-3"><a href="#cb278-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">0</span>][<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(2)</code></pre>
</div>
</div>
<div id="cell-295" class="cell">
<div class="sourceCode cell-code" id="cb280"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor </span></span>
<span id="cb280-2"><a href="#cb280-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb280-3"><a href="#cb280-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">1</span>, <span class="dv">10</span>).reshape(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb280-4"><a href="#cb280-4" aria-hidden="true" tabindex="-1"></a>x, x.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="499">
<pre><code>(tensor([[[1, 2, 3],
          [4, 5, 6],
          [7, 8, 9]]]),
 torch.Size([1, 3, 3]))</code></pre>
</div>
</div>
<p>Indexing values goes outer dimension -&gt; inner dimension (check out the square brackets).</p>
<div id="cell-297" class="cell">
<div class="sourceCode cell-code" id="cb282"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's index bracket by bracket</span></span>
<span id="cb282-2"><a href="#cb282-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First square bracket:</span><span class="ch">\n</span><span class="sc">{</span>x[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb282-3"><a href="#cb282-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Second square bracket: </span><span class="sc">{</span>x[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb282-4"><a href="#cb282-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Third square bracket: </span><span class="sc">{</span>x[<span class="dv">0</span>][<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>First square bracket:
tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])
Second square bracket: tensor([1, 2, 3])
Third square bracket: 1</code></pre>
</div>
</div>
<section id="pytorch-tensors-numpy" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-tensors-numpy">PyTorch tensors &amp; NumPy</h3>
<ul>
<li><p>Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.</p></li>
<li><p>The two main methods you’ll want to use for NumPy to PyTorch (and back again) are:</p>
<ul>
<li>torch.from_numpy(ndarray) - NumPy array -&gt; PyTorch tensor.</li>
<li>torch.Tensor.numpy() - PyTorch tensor -&gt; NumPy array.</li>
</ul></li>
</ul>
<div id="cell-300" class="cell">
<div class="sourceCode cell-code" id="cb284"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a><span class="co"># NumPy array to tensor</span></span>
<span id="cb284-2"><a href="#cb284-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb284-3"><a href="#cb284-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb284-4"><a href="#cb284-4" aria-hidden="true" tabindex="-1"></a>array <span class="op">=</span> np.arange(<span class="fl">1.0</span>, <span class="fl">8.0</span>)</span>
<span id="cb284-5"><a href="#cb284-5" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.from_numpy(array)</span>
<span id="cb284-6"><a href="#cb284-6" aria-hidden="true" tabindex="-1"></a>array, tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="513">
<pre><code>(array([1., 2., 3., 4., 5., 6., 7.]),
 tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it’ll keep the same datatype (as above). However, many PyTorch calculations default to using float32. So if you want to convert your NumPy array (float64) -&gt; PyTorch tensor (float64) -&gt; PyTorch tensor (float32), you can use tensor = torch.from_numpy(array).type(torch.float32).</p>
</blockquote>
<div id="cell-302" class="cell">
<div class="sourceCode cell-code" id="cb286"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.from_numpy(array).<span class="bu">type</span>(torch.float32)</span>
<span id="cb286-2"><a href="#cb286-2" aria-hidden="true" tabindex="-1"></a>tensor.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="519">
<pre><code>torch.float32</code></pre>
</div>
</div>
</section>
<section id="running-tensors-on-gpus-and-making-faster-computations" class="level3">
<h3 class="anchored" data-anchor-id="running-tensors-on-gpus-and-making-faster-computations">Running tensors on GPUs (and making faster computations)</h3>
<ul>
<li><p>Deep learning algorithms require a lot of numerical operations.</p></li>
<li><p>However, there’s another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs.</p></li>
</ul>
<p><img src="./GPU.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>How can I get GPU?</p>
</blockquote>
<ul>
<li><p>Buy Hardware, NVIDVIA. Guide for buying <a href="https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">GPU</a></p></li>
<li><p>Cloud computing (AWS, GCP, Azure etc)</p></li>
<li><p>Free: Colab, Kaggle,</p></li>
</ul>
<section id="cuda" class="level5">
<h5 class="anchored" data-anchor-id="cuda">CUDA</h5>
<div id="cell-308" class="cell">
<div class="sourceCode cell-code" id="cb288"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check if CUDA is available</span></span>
<span id="cb288-2"><a href="#cb288-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.is_available()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="523">
<pre><code>False</code></pre>
</div>
</div>
<div id="cell-309" class="cell">
<div class="sourceCode cell-code" id="cb290"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set device type</span></span>
<span id="cb290-2"><a href="#cb290-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb290-3"><a href="#cb290-3" aria-hidden="true" tabindex="-1"></a>device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="524">
<pre><code>'cpu'</code></pre>
</div>
</div>
<div id="cell-310" class="cell">
<div class="sourceCode cell-code" id="cb292"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb292-1"><a href="#cb292-1" aria-hidden="true" tabindex="-1"></a>torch.cuda.device_count() <span class="co"># count number of GPUs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="529">
<pre><code>0</code></pre>
</div>
</div>
</section>
<section id="mps-apple-metal-performance-shaders-mps-as-the-backend-for-pytorch" class="level4">
<h4 class="anchored" data-anchor-id="mps-apple-metal-performance-shaders-mps-as-the-backend-for-pytorch">MPS : Apple’ Metal Performance Shaders (MPS) as the backend for PyTorch</h4>
<div id="cell-312" class="cell">
<div class="sourceCode cell-code" id="cb294"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb294-1"><a href="#cb294-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)</span></span>
<span id="cb294-2"><a href="#cb294-2" aria-hidden="true" tabindex="-1"></a>torch.backends.mps.is_available()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="526">
<pre><code>True</code></pre>
</div>
</div>
<div id="cell-313" class="cell">
<div class="sourceCode cell-code" id="cb296"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb296-1"><a href="#cb296-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-2"><a href="#cb296-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the device      </span></span>
<span id="cb296-3"><a href="#cb296-3" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"mps"</span> <span class="cf">if</span> torch.backends.mps.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb296-4"><a href="#cb296-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using device: mps</code></pre>
</div>
</div>
</section>
</section>
<section id="putting-tensors-and-models-on-the-gpu" class="level3">
<h3 class="anchored" data-anchor-id="putting-tensors-and-models-on-the-gpu">Putting tensors (and models) on the GPU</h3>
<ul>
<li>You can put tensors (and models, we’ll see this later) on a specific device by calling to(device) on them.</li>
</ul>
<div id="cell-316" class="cell">
<div class="sourceCode cell-code" id="cb298"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb298-1"><a href="#cb298-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb298-2"><a href="#cb298-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb298-3"><a href="#cb298-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the device</span></span>
<span id="cb298-4"><a href="#cb298-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"mps"</span> <span class="cf">if</span> torch.backends.mps.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb298-5"><a href="#cb298-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb298-6"><a href="#cb298-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data and send it to the device</span></span>
<span id="cb298-7"><a href="#cb298-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">4</span>)).to(device)</span>
<span id="cb298-8"><a href="#cb298-8" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="539">
<pre><code>tensor([[0.8095, 0.0784, 0.3189, 0.0733],
        [0.7410, 0.3840, 0.9461, 0.1013],
        [0.1974, 0.8245, 0.5863, 0.9017]], device='mps:0')</code></pre>
</div>
</div>
<div id="cell-317" class="cell">
<div class="sourceCode cell-code" id="cb300"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create tensor (default on CPU)</span></span>
<span id="cb300-2"><a href="#cb300-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb300-3"><a href="#cb300-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-4"><a href="#cb300-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor not on GPU</span></span>
<span id="cb300-5"><a href="#cb300-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor, tensor.device)</span>
<span id="cb300-6"><a href="#cb300-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-7"><a href="#cb300-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Move tensor to GPU (if available)</span></span>
<span id="cb300-8"><a href="#cb300-8" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu <span class="op">=</span> tensor.to(device)</span>
<span id="cb300-9"><a href="#cb300-9" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1, 2, 3]) cpu</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="540">
<pre><code>tensor([1, 2, 3], device='mps:0')</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Notice the second tensor has device=‘mps:0’, this means it’s stored on the 0th GPU available (GPUs are 0 indexed, if two GPUs were available, they’d be ‘mps:0’ and ‘cuda:1’ respectively, up to ‘cuda:n’).</p>
</blockquote>
</section>
<section id="moving-tensors-back-to-the-cpu" class="level3">
<h3 class="anchored" data-anchor-id="moving-tensors-back-to-the-cpu">Moving tensors back to the CPU¶</h3>
<ul>
<li><p>We will use the .to(‘cpu’) method to move tensors back to the CPU.</p></li>
<li><p>If this object is already in CPU memory and on the correct device, then no copy is performed and the original object is returned.</p></li>
</ul>
<div id="cell-321" class="cell">
<div class="sourceCode cell-code" id="cb303"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb303-1"><a href="#cb303-1" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu <span class="co">#on GPU</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="543">
<pre><code>tensor([1, 2, 3], device='mps:0')</code></pre>
</div>
</div>
<div id="cell-322" class="cell">
<div class="sourceCode cell-code" id="cb305"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instead, copy the tensor back to cpu</span></span>
<span id="cb305-2"><a href="#cb305-2" aria-hidden="true" tabindex="-1"></a>tensor_back_on_cpu <span class="op">=</span> tensor_on_gpu.cpu()</span>
<span id="cb305-3"><a href="#cb305-3" aria-hidden="true" tabindex="-1"></a>tensor_back_on_cpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="542">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
<div id="cell-323" class="cell">
<div class="sourceCode cell-code" id="cb307"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb307-1"><a href="#cb307-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instead, copy the tensor back to cpu</span></span>
<span id="cb307-2"><a href="#cb307-2" aria-hidden="true" tabindex="-1"></a>tensor_back_to_numpy <span class="op">=</span> tensor_on_gpu.cpu().numpy()</span>
<span id="cb307-3"><a href="#cb307-3" aria-hidden="true" tabindex="-1"></a>tensor_back_to_numpy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="544">
<pre><code>array([1, 2, 3])</code></pre>
</div>
</div>
</section>
</section>
<section id="more-on-tensors" class="level2">
<h2 class="anchored" data-anchor-id="more-on-tensors">More on Tensors</h2>
<ul>
<li><p>Pytorch Beginner Tutorial <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">here</a>. This is a great tutorial for learning about Pytorch. Quickstart and Tensor Sections !</p></li>
<li><p>Learn more about Tensor representations <a href="https://www.youtube.com/watch?v=f5liqUk0ZTw&amp;ab_channel=DanFleisch">here</a></p></li>
</ul>
</section>
<section id="exercises" class="level2">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<p>The best way to master a topic is to solve problems. Here are some warm­up exercises. Many of the problems will require going through the official ocumentation and finding helpful functions.</p>
</section>
<section id="finding-the-min-max-mean-sum-etc-aggregation" class="level2">
<h2 class="anchored" data-anchor-id="finding-the-min-max-mean-sum-etc-aggregation">Finding the min, max, mean, sum, etc (aggregation)¶</h2>
<p>1 Create a 2D tensor and then add a dimension of size 1 inserted at dimension 0.</p>
<ol start="2" type="1">
<li><p>Remove the extra dimension you just added to the previous tensor.</p></li>
<li><p>Create a random tensor of shape 5x3 in the interval [3, 7)</p></li>
<li><p>Create a tensor with values from a normal distribution (mean=0, std=1).</p></li>
<li><p>Retrieve the indexes of all the nonzero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).</p></li>
<li><p>Create a random tensor of size (3,1) and then horizontally stack four copies together.</p></li>
<li><p>Return the batch matrix­matrix product of two three­dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).</p></li>
<li><p>Return the batch matrix­matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4))</p></li>
</ol>
</section>
<section id="indexing-slicing-and-joining" class="level2">
<h2 class="anchored" data-anchor-id="indexing-slicing-and-joining">Indexing, Slicing, and Joining</h2>
<ul>
<li>PyTorch’s indexing and slicing is similar to NumPy’s.</li>
</ul>
<section id="special-tensor-initializations" class="level3">
<h3 class="anchored" data-anchor-id="special-tensor-initializations">Special Tensor initializations</h3>
<p>We can create a vector of incremental numbers</p>
<div id="cell-329" class="cell">
<div class="sourceCode cell-code" id="cb309"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb309-1"><a href="#cb309-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb309-2"><a href="#cb309-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre>
</div>
</div>
<p>Sometimes it’s useful to have an integer-based arange for indexing</p>
<div id="cell-331" class="cell">
<div class="sourceCode cell-code" id="cb311"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb311-1"><a href="#cb311-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">10</span>).<span class="bu">long</span>()</span>
<span id="cb311-2"><a href="#cb311-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre>
</div>
</div>
</section>
</section>
<section id="operations" class="level2">
<h2 class="anchored" data-anchor-id="operations">Operations</h2>
<p>Using the tensors to do linear algebra is a foundation of modern Deep Learning practices</p>
<p>Reshaping allows you to move the numbers in a tensor around. One can be sure that the order is preserved. In PyTorch, reshaping is called <code>view</code></p>
<div id="cell-334" class="cell">
<div class="sourceCode cell-code" id="cb313"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">20</span>)</span>
<span id="cb313-2"><a href="#cb313-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb313-3"><a href="#cb313-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">1</span>, <span class="dv">20</span>))</span>
<span id="cb313-4"><a href="#cb313-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">2</span>, <span class="dv">10</span>))</span>
<span id="cb313-5"><a href="#cb313-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">4</span>, <span class="dv">5</span>))</span>
<span id="cb313-6"><a href="#cb313-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">5</span>, <span class="dv">4</span>))</span>
<span id="cb313-7"><a href="#cb313-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">10</span>, <span class="dv">2</span>))</span>
<span id="cb313-8"><a href="#cb313-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">20</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19]])
tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],
        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])
tensor([[ 0,  1,  2,  3,  4],
        [ 5,  6,  7,  8,  9],
        [10, 11, 12, 13, 14],
        [15, 16, 17, 18, 19]])
tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11],
        [12, 13, 14, 15],
        [16, 17, 18, 19]])
tensor([[ 0,  1],
        [ 2,  3],
        [ 4,  5],
        [ 6,  7],
        [ 8,  9],
        [10, 11],
        [12, 13],
        [14, 15],
        [16, 17],
        [18, 19]])
tensor([[ 0],
        [ 1],
        [ 2],
        [ 3],
        [ 4],
        [ 5],
        [ 6],
        [ 7],
        [ 8],
        [ 9],
        [10],
        [11],
        [12],
        [13],
        [14],
        [15],
        [16],
        [17],
        [18],
        [19]])</code></pre>
</div>
</div>
<p>We can use view to add size-1 dimensions, which can be useful for combining with other tensors. This is called broadcasting.</p>
<div id="cell-336" class="cell">
<div class="sourceCode cell-code" id="cb315"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb315-1"><a href="#cb315-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>).view(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb315-2"><a href="#cb315-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.arange(<span class="dv">4</span>).view(<span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb315-3"><a href="#cb315-3" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.arange(<span class="dv">3</span>).view(<span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb315-4"><a href="#cb315-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb315-5"><a href="#cb315-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb315-6"><a href="#cb315-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y)</span>
<span id="cb315-7"><a href="#cb315-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z)</span>
<span id="cb315-8"><a href="#cb315-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x <span class="op">+</span> y)</span>
<span id="cb315-9"><a href="#cb315-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x <span class="op">+</span> z)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
tensor([[0, 1, 2, 3]])
tensor([[0],
        [1],
        [2]])
tensor([[ 0,  2,  4,  6],
        [ 4,  6,  8, 10],
        [ 8, 10, 12, 14]])
tensor([[ 0,  1,  2,  3],
        [ 5,  6,  7,  8],
        [10, 11, 12, 13]])</code></pre>
</div>
</div>
<p>Unsqueeze and squeeze will add and remove 1-dimensions.</p>
<div id="cell-338" class="cell">
<div class="sourceCode cell-code" id="cb317"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb317-1"><a href="#cb317-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>).view(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb317-2"><a href="#cb317-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.shape)</span>
<span id="cb317-3"><a href="#cb317-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb317-4"><a href="#cb317-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.unsqueeze(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb317-5"><a href="#cb317-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.shape)</span>
<span id="cb317-6"><a href="#cb317-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb317-7"><a href="#cb317-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.squeeze()</span>
<span id="cb317-8"><a href="#cb317-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 4])
torch.Size([3, 1, 4])
torch.Size([3, 4])</code></pre>
</div>
</div>
<p>all of the standard mathematics operations apply (such as <code>add</code> below)</p>
<div id="cell-340" class="cell">
<div class="sourceCode cell-code" id="cb319"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb319-1"><a href="#cb319-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb319-2"><a href="#cb319-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb319-3"><a href="#cb319-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span>)</span>
<span id="cb319-4"><a href="#cb319-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"torch.add(x, x): </span><span class="ch">\n</span><span class="st">"</span>, torch.add(x, x))</span>
<span id="cb319-5"><a href="#cb319-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span>)</span>
<span id="cb319-6"><a href="#cb319-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x+x: </span><span class="ch">\n</span><span class="st">"</span>, x <span class="op">+</span> x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[0.6662, 0.3343, 0.7893, 0.3216],
        [0.5247, 0.6688, 0.8436, 0.4265],
        [0.9561, 0.0770, 0.4108, 0.0014]])
--
torch.add(x, x): 
 tensor([[1.3324, 0.6686, 1.5786, 0.6433],
        [1.0494, 1.3377, 1.6872, 0.8530],
        [1.9123, 0.1540, 0.8216, 0.0028]])
--
x+x: 
 tensor([[1.3324, 0.6686, 1.5786, 0.6433],
        [1.0494, 1.3377, 1.6872, 0.8530],
        [1.9123, 0.1540, 0.8216, 0.0028]])</code></pre>
</div>
</div>
<p>The convention of <code>_</code> indicating in-place operations continues:</p>
<div id="cell-342" class="cell">
<div class="sourceCode cell-code" id="cb321"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb321-1"><a href="#cb321-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>).reshape(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb321-2"><a href="#cb321-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb321-3"><a href="#cb321-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.add_(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
tensor([[ 0,  2,  4,  6],
        [ 8, 10, 12, 14],
        [16, 18, 20, 22]])</code></pre>
</div>
</div>
<p>There are many operations for which reduce a dimension. Such as sum:</p>
<div id="cell-344" class="cell">
<div class="sourceCode cell-code" id="cb323"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb323-1"><a href="#cb323-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>).reshape(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb323-2"><a href="#cb323-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb323-3"><a href="#cb323-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb323-4"><a href="#cb323-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Summing across rows (dim=0): </span><span class="ch">\n</span><span class="st">"</span>, x.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb323-5"><a href="#cb323-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb323-6"><a href="#cb323-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Summing across columns (dim=1): </span><span class="ch">\n</span><span class="st">"</span>, x.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
---
Summing across rows (dim=0): 
 tensor([12, 15, 18, 21])
---
Summing across columns (dim=1): 
 tensor([ 6, 22, 38])</code></pre>
</div>
</div>
<section id="indexing-slicing-joining-and-mutating" class="level4">
<h4 class="anchored" data-anchor-id="indexing-slicing-joining-and-mutating">Indexing, Slicing, Joining and Mutating</h4>
<div id="cell-346" class="cell">
<div class="sourceCode cell-code" id="cb325"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb325-1"><a href="#cb325-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb325-2"><a href="#cb325-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb325-3"><a href="#cb325-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb325-4"><a href="#cb325-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x[:2, :2]: </span><span class="ch">\n</span><span class="st">"</span>, x[:<span class="dv">2</span>, :<span class="dv">2</span>])</span>
<span id="cb325-5"><a href="#cb325-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb325-6"><a href="#cb325-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x[0][1]: </span><span class="ch">\n</span><span class="st">"</span>, x[<span class="dv">0</span>][<span class="dv">1</span>])</span>
<span id="cb325-7"><a href="#cb325-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb325-8"><a href="#cb325-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Setting [0][1] to be 8"</span>)</span>
<span id="cb325-9"><a href="#cb325-9" aria-hidden="true" tabindex="-1"></a>x[<span class="dv">0</span>][<span class="dv">1</span>] <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb325-10"><a href="#cb325-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[0, 1, 2],
        [3, 4, 5]])
---
x[:2, :2]: 
 tensor([[0, 1],
        [3, 4]])
---
x[0][1]: 
 tensor(1)
---
Setting [0][1] to be 8
tensor([[0, 8, 2],
        [3, 4, 5]])</code></pre>
</div>
</div>
<p>We can select a subset of a tensor using the <code>index_select</code></p>
<div id="cell-348" class="cell">
<div class="sourceCode cell-code" id="cb327"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb327-1"><a href="#cb327-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">9</span>).view(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb327-2"><a href="#cb327-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb327-3"><a href="#cb327-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb327-4"><a href="#cb327-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb327-5"><a href="#cb327-5" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> torch.LongTensor([<span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb327-6"><a href="#cb327-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.index_select(x, dim<span class="op">=</span><span class="dv">0</span>, index<span class="op">=</span>indices))</span>
<span id="cb327-7"><a href="#cb327-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb327-8"><a href="#cb327-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb327-9"><a href="#cb327-9" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> torch.LongTensor([<span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb327-10"><a href="#cb327-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.index_select(x, dim<span class="op">=</span><span class="dv">1</span>, index<span class="op">=</span>indices))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
---
tensor([[0, 1, 2],
        [6, 7, 8]])
---
tensor([[0, 2],
        [3, 5],
        [6, 8]])</code></pre>
</div>
</div>
<p>We can also use numpy-style advanced indexing:</p>
<div id="cell-350" class="cell">
<div class="sourceCode cell-code" id="cb329"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb329-1"><a href="#cb329-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">9</span>).view(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb329-2"><a href="#cb329-2" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> torch.LongTensor([<span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb329-3"><a href="#cb329-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb329-4"><a href="#cb329-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x[indices])</span>
<span id="cb329-5"><a href="#cb329-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb329-6"><a href="#cb329-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x[indices, :])</span>
<span id="cb329-7"><a href="#cb329-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb329-8"><a href="#cb329-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x[:, indices])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0, 1, 2],
        [6, 7, 8]])
---
tensor([[0, 1, 2],
        [6, 7, 8]])
---
tensor([[0, 2],
        [3, 5],
        [6, 8]])</code></pre>
</div>
</div>
<p>We can combine tensors by concatenating them. First, concatenating on the rows</p>
<div id="cell-352" class="cell">
<div class="sourceCode cell-code" id="cb331"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb331-1"><a href="#cb331-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb331-2"><a href="#cb331-2" aria-hidden="true" tabindex="-1"></a>describe(x)</span>
<span id="cb331-3"><a href="#cb331-3" aria-hidden="true" tabindex="-1"></a>describe(torch.cat([x, x], dim<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb331-4"><a href="#cb331-4" aria-hidden="true" tabindex="-1"></a>describe(torch.cat([x, x], dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb331-5"><a href="#cb331-5" aria-hidden="true" tabindex="-1"></a>describe(torch.stack([x, x]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.LongTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0, 1, 2],
        [3, 4, 5]])
Type: torch.LongTensor
Shape/size: torch.Size([4, 3])
Values: 
tensor([[0, 1, 2],
        [3, 4, 5],
        [0, 1, 2],
        [3, 4, 5]])
Type: torch.LongTensor
Shape/size: torch.Size([2, 6])
Values: 
tensor([[0, 1, 2, 0, 1, 2],
        [3, 4, 5, 3, 4, 5]])
Type: torch.LongTensor
Shape/size: torch.Size([2, 2, 3])
Values: 
tensor([[[0, 1, 2],
         [3, 4, 5]],

        [[0, 1, 2],
         [3, 4, 5]]])</code></pre>
</div>
</div>
<p>We can concentate along the first dimension.. the columns.</p>
<div id="cell-354" class="cell">
<div class="sourceCode cell-code" id="cb333"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb333-1"><a href="#cb333-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">9</span>).view(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb333-2"><a href="#cb333-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-3"><a href="#cb333-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb333-4"><a href="#cb333-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb333-5"><a href="#cb333-5" aria-hidden="true" tabindex="-1"></a>new_x <span class="op">=</span> torch.cat([x, x, x], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb333-6"><a href="#cb333-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_x.shape)</span>
<span id="cb333-7"><a href="#cb333-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
---
torch.Size([3, 9])
tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],
        [3, 4, 5, 3, 4, 5, 3, 4, 5],
        [6, 7, 8, 6, 7, 8, 6, 7, 8]])</code></pre>
</div>
</div>
<p>We can also concatenate on a new 0th dimension to “stack” the tensors:</p>
<div id="cell-356" class="cell">
<div class="sourceCode cell-code" id="cb335"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb335-1"><a href="#cb335-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">9</span>).view(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb335-2"><a href="#cb335-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb335-3"><a href="#cb335-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb335-4"><a href="#cb335-4" aria-hidden="true" tabindex="-1"></a>new_x <span class="op">=</span> torch.stack([x, x, x])</span>
<span id="cb335-5"><a href="#cb335-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_x.shape)</span>
<span id="cb335-6"><a href="#cb335-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
---
torch.Size([3, 3, 3])
tensor([[[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]],

        [[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]],

        [[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]]])</code></pre>
</div>
</div>
</section>
<section id="linear-algebra-tensor-functions" class="level4">
<h4 class="anchored" data-anchor-id="linear-algebra-tensor-functions">Linear Algebra Tensor Functions</h4>
<p>Transposing allows you to switch the dimensions to be on different axis. So we can make it so all the rows are columsn and vice versa.</p>
<div id="cell-359" class="cell">
<div class="sourceCode cell-code" id="cb337"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb337-1"><a href="#cb337-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">12</span>).view(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb337-2"><a href="#cb337-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x) </span>
<span id="cb337-3"><a href="#cb337-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb337-4"><a href="#cb337-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.tranpose(1, 0): </span><span class="ch">\n</span><span class="st">"</span>, x.transpose(<span class="dv">1</span>, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
---
x.tranpose(1, 0): 
 tensor([[ 0,  4,  8],
        [ 1,  5,  9],
        [ 2,  6, 10],
        [ 3,  7, 11]])</code></pre>
</div>
</div>
<p>A three dimensional tensor would represent a batch of sequences, where each sequence item has a feature vector. It is common to switch the batch and sequence dimensions so that we can more easily index the sequence in a sequence model.</p>
<p>Note: Transpose will only let you swap 2 axes. Permute (in the next cell) allows for multiple</p>
<div id="cell-361" class="cell">
<div class="sourceCode cell-code" id="cb339"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb339-1"><a href="#cb339-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb339-2"><a href="#cb339-2" aria-hidden="true" tabindex="-1"></a>seq_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb339-3"><a href="#cb339-3" aria-hidden="true" tabindex="-1"></a>feature_size <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb339-4"><a href="#cb339-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-5"><a href="#cb339-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(batch_size <span class="op">*</span> seq_size <span class="op">*</span> feature_size).view(batch_size, seq_size, feature_size)</span>
<span id="cb339-6"><a href="#cb339-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-7"><a href="#cb339-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.shape: </span><span class="ch">\n</span><span class="st">"</span>, x.shape)</span>
<span id="cb339-8"><a href="#cb339-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb339-9"><a href="#cb339-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-----"</span>)</span>
<span id="cb339-10"><a href="#cb339-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-11"><a href="#cb339-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.transpose(1, 0).shape: </span><span class="ch">\n</span><span class="st">"</span>, x.transpose(<span class="dv">1</span>, <span class="dv">0</span>).shape)</span>
<span id="cb339-12"><a href="#cb339-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.transpose(1, 0): </span><span class="ch">\n</span><span class="st">"</span>, x.transpose(<span class="dv">1</span>, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x.shape: 
 torch.Size([3, 4, 5])
x: 
 tensor([[[ 0,  1,  2,  3,  4],
         [ 5,  6,  7,  8,  9],
         [10, 11, 12, 13, 14],
         [15, 16, 17, 18, 19]],

        [[20, 21, 22, 23, 24],
         [25, 26, 27, 28, 29],
         [30, 31, 32, 33, 34],
         [35, 36, 37, 38, 39]],

        [[40, 41, 42, 43, 44],
         [45, 46, 47, 48, 49],
         [50, 51, 52, 53, 54],
         [55, 56, 57, 58, 59]]])
-----
x.transpose(1, 0).shape: 
 torch.Size([4, 3, 5])
x.transpose(1, 0): 
 tensor([[[ 0,  1,  2,  3,  4],
         [20, 21, 22, 23, 24],
         [40, 41, 42, 43, 44]],

        [[ 5,  6,  7,  8,  9],
         [25, 26, 27, 28, 29],
         [45, 46, 47, 48, 49]],

        [[10, 11, 12, 13, 14],
         [30, 31, 32, 33, 34],
         [50, 51, 52, 53, 54]],

        [[15, 16, 17, 18, 19],
         [35, 36, 37, 38, 39],
         [55, 56, 57, 58, 59]]])</code></pre>
</div>
</div>
<p>Permute is a more general version of tranpose:</p>
<div id="cell-363" class="cell">
<div class="sourceCode cell-code" id="cb341"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb341-1"><a href="#cb341-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb341-2"><a href="#cb341-2" aria-hidden="true" tabindex="-1"></a>seq_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb341-3"><a href="#cb341-3" aria-hidden="true" tabindex="-1"></a>feature_size <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb341-4"><a href="#cb341-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb341-5"><a href="#cb341-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(batch_size <span class="op">*</span> seq_size <span class="op">*</span> feature_size).view(batch_size, seq_size, feature_size)</span>
<span id="cb341-6"><a href="#cb341-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb341-7"><a href="#cb341-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.shape: </span><span class="ch">\n</span><span class="st">"</span>, x.shape)</span>
<span id="cb341-8"><a href="#cb341-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb341-9"><a href="#cb341-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-----"</span>)</span>
<span id="cb341-10"><a href="#cb341-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb341-11"><a href="#cb341-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.permute(1, 0, 2).shape: </span><span class="ch">\n</span><span class="st">"</span>, x.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>).shape)</span>
<span id="cb341-12"><a href="#cb341-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.permute(1, 0, 2): </span><span class="ch">\n</span><span class="st">"</span>, x.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x.shape: 
 torch.Size([3, 4, 5])
x: 
 tensor([[[ 0,  1,  2,  3,  4],
         [ 5,  6,  7,  8,  9],
         [10, 11, 12, 13, 14],
         [15, 16, 17, 18, 19]],

        [[20, 21, 22, 23, 24],
         [25, 26, 27, 28, 29],
         [30, 31, 32, 33, 34],
         [35, 36, 37, 38, 39]],

        [[40, 41, 42, 43, 44],
         [45, 46, 47, 48, 49],
         [50, 51, 52, 53, 54],
         [55, 56, 57, 58, 59]]])
-----
x.permute(1, 0, 2).shape: 
 torch.Size([4, 3, 5])
x.permute(1, 0, 2): 
 tensor([[[ 0,  1,  2,  3,  4],
         [20, 21, 22, 23, 24],
         [40, 41, 42, 43, 44]],

        [[ 5,  6,  7,  8,  9],
         [25, 26, 27, 28, 29],
         [45, 46, 47, 48, 49]],

        [[10, 11, 12, 13, 14],
         [30, 31, 32, 33, 34],
         [50, 51, 52, 53, 54]],

        [[15, 16, 17, 18, 19],
         [35, 36, 37, 38, 39],
         [55, 56, 57, 58, 59]]])</code></pre>
</div>
</div>
<p>Matrix multiplication is <code>mm</code>:</p>
<div id="cell-365" class="cell">
<div class="sourceCode cell-code" id="cb343"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb343-1"><a href="#cb343-1" aria-hidden="true" tabindex="-1"></a>torch.randn(<span class="dv">2</span>, <span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>tensor([[-0.4790,  0.8539, -0.2285],
        [ 0.3081,  1.1171,  0.1585]], requires_grad=True)</code></pre>
</div>
</div>
<div id="cell-366" class="cell">
<div class="sourceCode cell-code" id="cb345"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb345-1"><a href="#cb345-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">2</span>, <span class="dv">3</span>).<span class="bu">float</span>()</span>
<span id="cb345-2"><a href="#cb345-2" aria-hidden="true" tabindex="-1"></a>describe(x1)</span>
<span id="cb345-3"><a href="#cb345-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb345-4"><a href="#cb345-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> torch.ones(<span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb345-5"><a href="#cb345-5" aria-hidden="true" tabindex="-1"></a>x2[:, <span class="dv">1</span>] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb345-6"><a href="#cb345-6" aria-hidden="true" tabindex="-1"></a>describe(x2)</span>
<span id="cb345-7"><a href="#cb345-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb345-8"><a href="#cb345-8" aria-hidden="true" tabindex="-1"></a>describe(torch.mm(x1, x2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0., 1., 2.],
        [3., 4., 5.]])
Type: torch.FloatTensor
Shape/size: torch.Size([3, 2])
Values: 
tensor([[1., 2.],
        [1., 2.],
        [1., 2.]])
Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[ 3.,  6.],
        [12., 24.]])</code></pre>
</div>
</div>
<div id="cell-367" class="cell">
<div class="sourceCode cell-code" id="cb347"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb347-1"><a href="#cb347-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">12</span>).view(<span class="dv">3</span>,<span class="dv">4</span>).<span class="bu">float</span>()</span>
<span id="cb347-2"><a href="#cb347-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb347-3"><a href="#cb347-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-4"><a href="#cb347-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> torch.ones(<span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb347-5"><a href="#cb347-5" aria-hidden="true" tabindex="-1"></a>x2[:, <span class="dv">1</span>] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb347-6"><a href="#cb347-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x2)</span>
<span id="cb347-7"><a href="#cb347-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-8"><a href="#cb347-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.mm(x2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.]])
tensor([[1., 2.],
        [1., 2.],
        [1., 2.],
        [1., 2.]])
tensor([[ 6., 12.],
        [22., 44.],
        [38., 76.]])</code></pre>
</div>
</div>
<p>See the <a href="https://pytorch.org/docs/stable/torch.html#math-operations">PyTorch Math Operations Documentation</a> for more!</p>
</section>
</section>
<section id="computing-gradients" class="level2">
<h2 class="anchored" data-anchor-id="computing-gradients">Computing Gradients</h2>
<div id="cell-370" class="cell">
<div class="sourceCode cell-code" id="cb349"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb349-1"><a href="#cb349-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">2.0</span>, <span class="fl">3.0</span>]], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb349-2"><a href="#cb349-2" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> <span class="dv">3</span> <span class="op">*</span> x</span>
<span id="cb349-3"><a href="#cb349-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[6., 9.]], grad_fn=&lt;MulBackward0&gt;)</code></pre>
</div>
</div>
<p>In this small snippet, you can see the gradient computations at work. We create a tensor and multiply it by 3. Then, we create a scalar output using <code>sum()</code>. A Scalar output is needed as the the loss variable. Then, called backward on the loss means it computes its rate of change with respect to the inputs. Since the scalar was created with sum, each position in z and x are independent with respect to the loss scalar.</p>
<p>The rate of change of x with respect to the output is just the constant 3 that we multiplied x by.</p>
<div id="cell-372" class="cell">
<div class="sourceCode cell-code" id="cb351"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb351-1"><a href="#cb351-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">2.0</span>, <span class="fl">3.0</span>]], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb351-2"><a href="#cb351-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb351-3"><a href="#cb351-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb351-4"><a href="#cb351-4" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> <span class="dv">3</span> <span class="op">*</span> x</span>
<span id="cb351-5"><a href="#cb351-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"z = 3*x: </span><span class="ch">\n</span><span class="st">"</span>, z)</span>
<span id="cb351-6"><a href="#cb351-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb351-7"><a href="#cb351-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-8"><a href="#cb351-8" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> z.<span class="bu">sum</span>()</span>
<span id="cb351-9"><a href="#cb351-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss = z.sum(): </span><span class="ch">\n</span><span class="st">"</span>, loss)</span>
<span id="cb351-10"><a href="#cb351-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb351-11"><a href="#cb351-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-12"><a href="#cb351-12" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb351-13"><a href="#cb351-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-14"><a href="#cb351-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"after loss.backward(), x.grad: </span><span class="ch">\n</span><span class="st">"</span>, x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[2., 3.]], requires_grad=True)
---
z = 3*x: 
 tensor([[6., 9.]], grad_fn=&lt;MulBackward0&gt;)
---
loss = z.sum(): 
 tensor(15., grad_fn=&lt;SumBackward0&gt;)
---
after loss.backward(), x.grad: 
 tensor([[3., 3.]])</code></pre>
</div>
</div>
<section id="example-computing-a-conditional-gradient" class="level3">
<h3 class="anchored" data-anchor-id="example-computing-a-conditional-gradient">Example: Computing a conditional gradient</h3>
<p><span class="math display">\[ \text{ Find the gradient of f(x) at x=1 } \]</span> <span class="math display">\[ {} \]</span> <span class="math display">\[ f(x)=\left\{
\begin{array}{ll}
    sin(x) \text{ if } x&gt;0 \\
    cos(x) \text{ otherwise } \\
\end{array}
\right.\]</span></p>
<div id="cell-374" class="cell">
<div class="sourceCode cell-code" id="cb353"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb353-1"><a href="#cb353-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb353-2"><a href="#cb353-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (x.data <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">all</span>():</span>
<span id="cb353-3"><a href="#cb353-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sin(x)</span>
<span id="cb353-4"><a href="#cb353-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb353-5"><a href="#cb353-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cos(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-375" class="cell">
<div class="sourceCode cell-code" id="cb354"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb354-1"><a href="#cb354-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb354-2"><a href="#cb354-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb354-3"><a href="#cb354-3" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb354-4"><a href="#cb354-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.5403])</code></pre>
</div>
</div>
<p>We could apply this to a larger vector too, but we need to make sure the output is a scalar:</p>
<div id="cell-377" class="cell">
<div class="sourceCode cell-code" id="cb356"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb356-1"><a href="#cb356-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">0.5</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb356-2"><a href="#cb356-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb356-3"><a href="#cb356-3" aria-hidden="true" tabindex="-1"></a><span class="co"># this is meant to break!</span></span>
<span id="cb356-4"><a href="#cb356-4" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb356-5"><a href="#cb356-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: grad can be implicitly created only for scalar outputs</code></pre>
</div>
</div>
<p>Making the output a scalar:</p>
<div id="cell-379" class="cell">
<div class="sourceCode cell-code" id="cb358"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb358-1"><a href="#cb358-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">0.5</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb358-2"><a href="#cb358-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb358-3"><a href="#cb358-3" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb358-4"><a href="#cb358-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.5403, 0.8776])</code></pre>
</div>
</div>
<p>but there was an issue.. this isn’t right for this edge case:</p>
<div id="cell-381" class="cell">
<div class="sourceCode cell-code" id="cb360"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb360-1"><a href="#cb360-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="op">-</span><span class="dv">1</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb360-2"><a href="#cb360-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb360-3"><a href="#cb360-3" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb360-4"><a href="#cb360-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([-0.8415,  0.8415])</code></pre>
</div>
</div>
<div id="cell-382" class="cell">
<div class="sourceCode cell-code" id="cb362"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb362-1"><a href="#cb362-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">0.5</span>, <span class="op">-</span><span class="dv">1</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb362-2"><a href="#cb362-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb362-3"><a href="#cb362-3" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb362-4"><a href="#cb362-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.4794, 0.8415])</code></pre>
</div>
</div>
<p>This is because we aren’t doing the boolean computation and subsequent application of cos and sin on an elementwise basis. So, to solve this, it is common to use masking:</p>
<div id="cell-384" class="cell">
<div class="sourceCode cell-code" id="cb364"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb364-1"><a href="#cb364-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f2(x):</span>
<span id="cb364-2"><a href="#cb364-2" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> torch.gt(x, <span class="dv">0</span>).<span class="bu">float</span>()</span>
<span id="cb364-3"><a href="#cb364-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mask <span class="op">*</span> torch.sin(x) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> mask) <span class="op">*</span> torch.cos(x)</span>
<span id="cb364-4"><a href="#cb364-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb364-5"><a href="#cb364-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="op">-</span><span class="dv">1</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb364-6"><a href="#cb364-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f2(x)</span>
<span id="cb364-7"><a href="#cb364-7" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb364-8"><a href="#cb364-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.5403, 0.8415])</code></pre>
</div>
</div>
<div id="cell-385" class="cell">
<div class="sourceCode cell-code" id="cb366"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb366-1"><a href="#cb366-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> describe_grad(x):</span>
<span id="cb366-2"><a href="#cb366-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x.grad <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb366-3"><a href="#cb366-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"No gradient information"</span>)</span>
<span id="cb366-4"><a href="#cb366-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb366-5"><a href="#cb366-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Gradient: </span><span class="ch">\n</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(x.grad))</span>
<span id="cb366-6"><a href="#cb366-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Gradient Function: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(x.grad_fn))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-387" class="cell">
<div class="sourceCode cell-code" id="cb367"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb367-1"><a href="#cb367-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb367-2"><a href="#cb367-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb367-3"><a href="#cb367-3" aria-hidden="true" tabindex="-1"></a>describe(x)</span>
<span id="cb367-4"><a href="#cb367-4" aria-hidden="true" tabindex="-1"></a>describe_grad(x)</span>
<span id="cb367-5"><a href="#cb367-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--------"</span>)</span>
<span id="cb367-6"><a href="#cb367-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb367-7"><a href="#cb367-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x <span class="op">+</span> <span class="dv">2</span>) <span class="op">*</span> (x <span class="op">+</span> <span class="dv">5</span>) <span class="op">+</span> <span class="dv">3</span></span>
<span id="cb367-8"><a href="#cb367-8" aria-hidden="true" tabindex="-1"></a>describe(y)</span>
<span id="cb367-9"><a href="#cb367-9" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> y.mean()</span>
<span id="cb367-10"><a href="#cb367-10" aria-hidden="true" tabindex="-1"></a>describe(z)</span>
<span id="cb367-11"><a href="#cb367-11" aria-hidden="true" tabindex="-1"></a>describe_grad(x)</span>
<span id="cb367-12"><a href="#cb367-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--------"</span>)</span>
<span id="cb367-13"><a href="#cb367-13" aria-hidden="true" tabindex="-1"></a>z.backward(create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb367-14"><a href="#cb367-14" aria-hidden="true" tabindex="-1"></a>describe_grad(x)</span>
<span id="cb367-15"><a href="#cb367-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--------"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
No gradient information
--------
Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[21., 21.],
        [21., 21.]], grad_fn=&lt;AddBackward0&gt;)
Type: torch.FloatTensor
Shape/size: torch.Size([])
Values: 
21.0
No gradient information
--------
Gradient: 
tensor([[2.2500, 2.2500],
        [2.2500, 2.2500]], grad_fn=&lt;CloneBackward&gt;)
Gradient Function: None
--------</code></pre>
</div>
</div>
<div id="cell-388" class="cell">
<div class="sourceCode cell-code" id="cb369"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb369-1"><a href="#cb369-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-389" class="cell">
<div class="sourceCode cell-code" id="cb370"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb370-1"><a href="#cb370-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">+</span> <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-390" class="cell">
<div class="sourceCode cell-code" id="cb371"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb371-1"><a href="#cb371-1" aria-hidden="true" tabindex="-1"></a>y.grad_fn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>&lt;AddBackward0 at 0x7f35ea134940&gt;</code></pre>
</div>
</div>
</section>
<section id="cuda-tensors" class="level3">
<h3 class="anchored" data-anchor-id="cuda-tensors">CUDA Tensors</h3>
<p>PyTorch’s operations can seamlessly be used on the GPU or on the CPU. There are a couple basic operations for interacting in this way.</p>
<div id="cell-393" class="cell">
<div class="sourceCode cell-code" id="cb373"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb373-1"><a href="#cb373-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.cuda.is_available())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div id="cell-394" class="cell">
<div class="sourceCode cell-code" id="cb375"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb375-1"><a href="#cb375-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb375-2"><a href="#cb375-2" aria-hidden="true" tabindex="-1"></a>describe(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.FloatTensor
Shape/size: torch.Size([3, 3])
Values: 
tensor([[0.9149, 0.3993, 0.1100],
        [0.2541, 0.4333, 0.4451],
        [0.4966, 0.7865, 0.6604]])</code></pre>
</div>
</div>
<div id="cell-395" class="cell">
<div class="sourceCode cell-code" id="cb377"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb377-1"><a href="#cb377-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb377-2"><a href="#cb377-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>cuda</code></pre>
</div>
</div>
<div id="cell-396" class="cell">
<div class="sourceCode cell-code" id="cb379"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb379-1"><a href="#cb379-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">3</span>).to(device)</span>
<span id="cb379-2"><a href="#cb379-2" aria-hidden="true" tabindex="-1"></a>describe(x)</span>
<span id="cb379-3"><a href="#cb379-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.cuda.FloatTensor
Shape/size: torch.Size([3, 3])
Values: 
tensor([[0.1303, 0.3498, 0.3824],
        [0.8043, 0.3186, 0.2908],
        [0.4196, 0.3728, 0.3769]], device='cuda:0')
cuda:0</code></pre>
</div>
</div>
<div id="cell-397" class="cell">
<div class="sourceCode cell-code" id="cb381"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb381-1"><a href="#cb381-1" aria-hidden="true" tabindex="-1"></a>cpu_device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-398" class="cell">
<div class="sourceCode cell-code" id="cb382"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb382-1"><a href="#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this will break!</span></span>
<span id="cb382-2"><a href="#cb382-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb382-3"><a href="#cb382-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">+</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: expected type torch.cuda.FloatTensor but got torch.FloatTensor</code></pre>
</div>
</div>
<div id="cell-399" class="cell">
<div class="sourceCode cell-code" id="cb384"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb384-1"><a href="#cb384-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.to(cpu_device)</span>
<span id="cb384-2"><a href="#cb384-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(cpu_device)</span>
<span id="cb384-3"><a href="#cb384-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">+</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>tensor([[0.8394, 0.5273, 0.8267],
        [0.9273, 1.2824, 1.0603],
        [0.4574, 0.5968, 1.0541]])</code></pre>
</div>
</div>
<div id="cell-400" class="cell">
<div class="sourceCode cell-code" id="cb386"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb386-1"><a href="#cb386-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available(): <span class="co"># only is GPU is available</span></span>
<span id="cb386-2"><a href="#cb386-2" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>).to(device<span class="op">=</span><span class="st">'cuda:0'</span>) <span class="co">#  CUDA Tensor</span></span>
<span id="cb386-3"><a href="#cb386-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(a)</span>
<span id="cb386-4"><a href="#cb386-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb386-5"><a href="#cb386-5" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>).cuda()</span>
<span id="cb386-6"><a href="#cb386-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(b)</span>
<span id="cb386-7"><a href="#cb386-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-8"><a href="#cb386-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(a <span class="op">+</span> b)</span>
<span id="cb386-9"><a href="#cb386-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-10"><a href="#cb386-10" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> a.cpu() <span class="co"># Error expected</span></span>
<span id="cb386-11"><a href="#cb386-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(a <span class="op">+</span> b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.5274, 0.6325, 0.0910],
        [0.2323, 0.7269, 0.1187],
        [0.3951, 0.7199, 0.7595]], device='cuda:0')
tensor([[0.5311, 0.6449, 0.7224],
        [0.4416, 0.3634, 0.8818],
        [0.9874, 0.7316, 0.2814]], device='cuda:0')
tensor([[1.0585, 1.2775, 0.8134],
        [0.6739, 1.0903, 1.0006],
        [1.3825, 1.4515, 1.0409]], device='cuda:0')</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: expected type torch.FloatTensor but got torch.cuda.FloatTensor</code></pre>
</div>
</div>
</section>
<section id="exercises-1" class="level3">
<h3 class="anchored" data-anchor-id="exercises-1">Exercises</h3>
<p>Some of these exercises require operations not covered in the notebook. You will have to look at <a href="https://pytorch.org/docs/">the documentation</a> (on purpose!)</p>
<p>(Answers are at the bottom)</p>
<section id="exercise-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-1">Exercise 1</h4>
<p>Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis.</p>
</section>
<section id="exercise-2" class="level4">
<h4 class="anchored" data-anchor-id="exercise-2">Exercise 2</h4>
<p>Remove the extra dimension you just added to the previous tensor.</p>
</section>
<section id="exercise-3" class="level4">
<h4 class="anchored" data-anchor-id="exercise-3">Exercise 3</h4>
<p>Create a random tensor of shape 5x3 in the interval [3, 7)</p>
</section>
<section id="exercise-4" class="level4">
<h4 class="anchored" data-anchor-id="exercise-4">Exercise 4</h4>
<p>Create a tensor with values from a normal distribution (mean=0, std=1).</p>
</section>
<section id="exercise-5" class="level4">
<h4 class="anchored" data-anchor-id="exercise-5">Exercise 5</h4>
<p>Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).</p>
</section>
<section id="exercise-6" class="level4">
<h4 class="anchored" data-anchor-id="exercise-6">Exercise 6</h4>
<p>Create a random tensor of size (3,1) and then horizonally stack 4 copies together.</p>
</section>
<section id="exercise-7" class="level4">
<h4 class="anchored" data-anchor-id="exercise-7">Exercise 7</h4>
<p>Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).</p>
</section>
<section id="exercise-8" class="level4">
<h4 class="anchored" data-anchor-id="exercise-8">Exercise 8</h4>
<p>Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)).</p>
<p>Answers below</p>
<p>Answers still below.. Keep Going</p>
</section>
<section id="exercise-1-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-1-1">Exercise 1</h4>
<p>Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis.</p>
<div id="cell-434" class="cell">
<div class="sourceCode cell-code" id="cb389"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb389-1"><a href="#cb389-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb389-2"><a href="#cb389-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> a.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb389-3"><a href="#cb389-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a)</span>
<span id="cb389-4"><a href="#cb389-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exercise-2-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-2-1">Exercise 2</h4>
<p>Remove the extra dimension you just added to the previous tensor.</p>
<div id="cell-436" class="cell">
<div class="sourceCode cell-code" id="cb390"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb390-1"><a href="#cb390-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> a.squeeze(<span class="dv">0</span>)</span>
<span id="cb390-2"><a href="#cb390-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exercise-3-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-3-1">Exercise 3</h4>
<p>Create a random tensor of shape 5x3 in the interval [3, 7)</p>
<div id="cell-438" class="cell">
<div class="sourceCode cell-code" id="cb391"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb391-1"><a href="#cb391-1" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> <span class="op">+</span> torch.rand(<span class="dv">5</span>, <span class="dv">3</span>) <span class="op">*</span> <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exercise-4-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-4-1">Exercise 4</h4>
<p>Create a tensor with values from a normal distribution (mean=0, std=1).</p>
<div id="cell-440" class="cell">
<div class="sourceCode cell-code" id="cb392"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb392-1"><a href="#cb392-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb392-2"><a href="#cb392-2" aria-hidden="true" tabindex="-1"></a>a.normal_(mean<span class="op">=</span><span class="dv">0</span>, std<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exercise-5-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-5-1">Exercise 5</h4>
<p>Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).</p>
<div id="cell-442" class="cell">
<div class="sourceCode cell-code" id="cb393"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb393-1"><a href="#cb393-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.Tensor([<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb393-2"><a href="#cb393-2" aria-hidden="true" tabindex="-1"></a>torch.nonzero(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exercise-6-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-6-1">Exercise 6</h4>
<p>Create a random tensor of size (3,1) and then horizonally stack 4 copies together.</p>
<div id="cell-444" class="cell">
<div class="sourceCode cell-code" id="cb394"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb394-1"><a href="#cb394-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb394-2"><a href="#cb394-2" aria-hidden="true" tabindex="-1"></a>a.expand(<span class="dv">3</span>,<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exercise-7-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-7-1">Exercise 7</h4>
<p>Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).</p>
<div id="cell-446" class="cell">
<div class="sourceCode cell-code" id="cb395"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb395-1"><a href="#cb395-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)</span>
<span id="cb395-2"><a href="#cb395-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">4</span>)</span>
<span id="cb395-3"><a href="#cb395-3" aria-hidden="true" tabindex="-1"></a>torch.bmm(a, b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exercise-8-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-8-1">Exercise 8</h4>
<p>Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)).</p>
<div id="cell-448" class="cell">
<div class="sourceCode cell-code" id="cb396"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb396-1"><a href="#cb396-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)</span>
<span id="cb396-2"><a href="#cb396-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.rand(<span class="dv">5</span>,<span class="dv">4</span>)</span>
<span id="cb396-3"><a href="#cb396-3" aria-hidden="true" tabindex="-1"></a>torch.bmm(a, b.unsqueeze(<span class="dv">0</span>).expand(a.size(<span class="dv">0</span>), <span class="op">*</span>b.size()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="end" class="level3">
<h3 class="anchored" data-anchor-id="end">END</h3>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    if (id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        return container.innerHTML
      } else {
        return note.innerHTML;
      }
    } else {
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      try { hash = new URL(url).hash; } catch {}
      const id = hash.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note !== null) {
        try {
          const html = processXRef(id, note);
          instance.setContent(html);
        } finally {
          instance.enable();
          instance.show();
        }
      } else {
        // See if we can fetch this
        fetch(url.split('#')[0])
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.getElementById(id);
          console.log(htmlDoc.body.innerHTML);
          if (note !== null) {
            const html = processXRef(id, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="shmuhammad2004/shmuhammadblog" data-repo-id="R_kgDOHb5q2A" data-category="Announcements" data-category-id="DIC_kwDOHb5q2M4CPbHo" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="light">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../license.html">
<p>License</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>